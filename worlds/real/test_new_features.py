#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ–°å¢åŠŸèƒ½çš„ä¸“é—¨è„šæœ¬
éªŒè¯æ–°æ·»åŠ çš„æ–¹æ³•æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import sys
import json
import numpy as np
from datetime import datetime

# å¯¼å…¥ç³»ç»Ÿç»„ä»¶
try:
    from transfer_evaluator import TransferEvaluator
    from performance_analyzer import PerformanceAnalyzer
    print("âœ“ æ–°åŠŸèƒ½æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def test_transfer_evaluator_new_features():
    """æµ‹è¯• TransferEvaluator çš„æ–°å¢åŠŸèƒ½"""
    print("\n=== æµ‹è¯• TransferEvaluator æ–°åŠŸèƒ½ ===")
    
    try:
        # åˆå§‹åŒ–è¯„ä¼°å™¨
        evaluator = TransferEvaluator()
        print("âœ“ è¿ç§»è¯„ä¼°å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        adapted_strategy = {
            "strategy_type": "grab_and_move",
            "minecraft_performance": 0.85,
            "mapped_strategy_id": "test_adapted"
        }
        
        execution_results = {
            "execution_data": [
                {
                    "actual_position": [0.9, 1.1, 1.0],
                    "target_position": [1.0, 1.0, 1.0],
                    "actual_orientation": [0.1, 0.0, 0.0],
                    "target_orientation": [0.0, 0.0, 0.0],
                    "success": True,
                    "execution_time": 2.5,
                    "completed": True,
                    "error_count": 0,
                    "final_state_correct": True
                },
                {
                    "actual_position": [1.1, 0.9, 1.1],
                    "target_position": [1.0, 1.0, 1.0],
                    "actual_orientation": [0.0, 0.1, 0.0],
                    "target_orientation": [0.0, 0.0, 0.0],
                    "success": True,
                    "execution_time": 2.3,
                    "completed": True,
                    "error_count": 1,
                    "final_state_correct": True
                }
            ],
            "overall_score": 0.82,
            "performance_by_complexity": {1: 0.85, 2: 0.78, 3: 0.75}
        }
        
        # æµ‹è¯•1ï¼šæ·±å…¥è¿ç§»è´¨é‡åˆ†æ
        print("\n--- æµ‹è¯•1: æ·±å…¥è¿ç§»è´¨é‡åˆ†æ ---")
        quality_analysis = evaluator.analyze_transfer_quality(
            adapted_strategy, execution_results, 
            quality_dimensions=['precision', 'consistency', 'efficiency']
        )
        print(f"âœ“ è¿ç§»è´¨é‡åˆ†æå®Œæˆ")
        print(f"  ç»¼åˆè´¨é‡åˆ†æ•°: {quality_analysis['overall_quality_score']:.2f}")
        print(f"  è´¨é‡ç­‰çº§: {quality_analysis['quality_grade']}")
        print(f"  åˆ†æç»´åº¦: {len(quality_analysis['quality_dimensions'])}")
        print(f"  å‘ç°è´¨é‡é—®é¢˜: {len(quality_analysis['quality_issues'])} ä¸ª")
        
        # æµ‹è¯•2ï¼šå¤šç­–ç•¥å¯¹æ¯”åˆ†æ
        print("\n--- æµ‹è¯•2: å¤šç­–ç•¥å¯¹æ¯”åˆ†æ ---")
        strategies_data = {
            'strategy_a': {
                'strategy': {
                    'strategy_type': 'grab_and_move',
                    'mapped_strategy_id': 'test_a'
                },
                'results': {
                    'execution_data': [
                        {'actual_position': [0.9, 1.1, 1.0], 'target_position': [1.0, 1.0, 1.0], 'success': True, 'execution_time': 2.0},
                        {'actual_position': [1.1, 0.9, 1.1], 'target_position': [1.0, 1.0, 1.0], 'success': True, 'execution_time': 2.2}
                    ],
                    'overall_score': 0.85
                }
            },
            'strategy_b': {
                'strategy': {
                    'strategy_type': 'precision_grab',
                    'mapped_strategy_id': 'test_b'
                },
                'results': {
                    'execution_data': [
                        {'actual_position': [0.95, 1.05, 1.0], 'target_position': [1.0, 1.0, 1.0], 'success': True, 'execution_time': 2.8},
                        {'actual_position': [1.05, 0.95, 1.0], 'target_position': [1.0, 1.0, 1.0], 'success': True, 'execution_time': 2.9}
                    ],
                    'overall_score': 0.92
                }
            }
        }
        
        strategy_comparison = evaluator.compare_strategies(strategies_data)
        print(f"âœ“ ç­–ç•¥å¯¹æ¯”åˆ†æå®Œæˆ")
        print(f"  å¯¹æ¯”ç­–ç•¥æ•°: {strategy_comparison['strategies_count']}")
        print(f"  æœ€ä½³ç­–ç•¥: {strategy_comparison['best_strategy']}")
        print(f"  å¹³å‡æ€§èƒ½: {strategy_comparison['analysis_summary']['average_performance']:.2f}")
        print(f"  é€‰æ‹©å»ºè®®æ•°: {len(strategy_comparison['selection_recommendations'])}")
        
        # æµ‹è¯•3ï¼šæ”¹è¿›å»ºè®®ç”Ÿæˆ
        print("\n--- æµ‹è¯•3: æ”¹è¿›å»ºè®®ç”Ÿæˆ ---")
        evaluation_result = {
            'overall_score': 0.75,
            'metrics': {'accuracy': 0.7, 'success_rate': 0.8, 'execution_time': 0.6},
            'performance_comparison': {
                'target_performance': {
                    'degradation_areas': [{'metric': 'execution_time', 'percentage': 15}]
                }
            },
            'statistical_analysis': {
                'confidence_interval': {'margin_of_error': 0.05}
            }
        }
        
        improvement_suggestions = evaluator.generate_improvement_suggestions(
            evaluation_result, suggestion_type="comprehensive"
        )
        print(f"âœ“ æ”¹è¿›å»ºè®®ç”Ÿæˆå®Œæˆ")
        print(f"  å»ºè®®ç±»å‹: {improvement_suggestions['suggestion_type']}")
        print(f"  æ€»å»ºè®®æ•°: {improvement_suggestions['recommendations_summary']['total_recommendations']}")
        print(f"  ç½®ä¿¡åº¦: {improvement_suggestions['confidence_level']:.2f}")
        print(f"  å½“å‰æ€§èƒ½: {improvement_suggestions['current_performance']['overall_score']:.2f}")
        
        print("\nâœ“ æ‰€æœ‰ TransferEvaluator æ–°åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— TransferEvaluator æ–°åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_performance_analyzer_new_features():
    """æµ‹è¯• PerformanceAnalyzer çš„æ–°å¢åŠŸèƒ½"""
    print("\n=== æµ‹è¯• PerformanceAnalyzer æ–°åŠŸèƒ½ ===")
    
    try:
        # åˆå§‹åŒ–æ€§èƒ½åˆ†æå™¨
        analyzer = PerformanceAnalyzer()
        print("âœ“ æ€§èƒ½åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•1ï¼šæ€§èƒ½è¶‹åŠ¿é¢„æµ‹
        print("\n--- æµ‹è¯•1: æ€§èƒ½è¶‹åŠ¿é¢„æµ‹ ---")
        performance_history = {
            'accuracy': [0.7, 0.75, 0.8, 0.82, 0.85],
            'success_rate': [0.8, 0.82, 0.85, 0.87, 0.9],
            'execution_time': [3.0, 2.8, 2.6, 2.5, 2.4]
        }
        
        trend_prediction = analyzer.predict_performance_trend(
            performance_history, prediction_horizon=5, confidence_level=0.95
        )
        print(f"âœ“ æ€§èƒ½è¶‹åŠ¿é¢„æµ‹å®Œæˆ")
        print(f"  é¢„æµ‹æŒ‡æ ‡æ•°: {trend_prediction['prediction_metadata']['metrics_predicted']}")
        print(f"  æ•´ä½“è¶‹åŠ¿: {trend_prediction['overall_trend']['overall_direction']}")
        print(f"  é¢„æµ‹ç½®ä¿¡åº¦: {trend_prediction['prediction_confidence']:.2f}")
        print(f"  é¢„æµ‹è´¨é‡: {trend_prediction['prediction_metadata']['prediction_quality']}")
        
        # æµ‹è¯•2ï¼šç³»ç»Ÿç“¶é¢ˆè¯†åˆ«
        print("\n--- æµ‹è¯•2: ç³»ç»Ÿç“¶é¢ˆè¯†åˆ« ---")
        performance_metrics = {
            'accuracy': {
                'current_value': 0.75,
                'target_value': 0.9,
                'trend': 'stable'
            },
            'execution_time': {
                'current_value': 3.0,
                'target_value': 2.0,
                'trend': 'declining'
            }
        }
        
        resource_utilization = {
            'cpu': 0.95,  # CPUåˆ©ç”¨ç‡95%ï¼Œç“¶é¢ˆ
            'memory': 0.6,
            'storage': 0.3
        }
        
        system_constraints = {
            'max_concurrent_tasks': {
                'current_limit': 10,
                'required_capacity': 15
            }
        }
        
        bottleneck_analysis = analyzer.identify_bottlenecks(
            performance_metrics, resource_utilization, system_constraints
        )
        print(f"âœ“ ç³»ç»Ÿç“¶é¢ˆè¯†åˆ«å®Œæˆ")
        print(f"  å‘ç°ç“¶é¢ˆæ•°: {bottleneck_analysis['analysis_summary']['total_bottlenecks_identified']}")
        print(f"  ä¸¥é‡ç¨‹åº¦: {bottleneck_analysis['bottleneck_severity']['overall_severity']}")
        print(f"  åˆ†æç½®ä¿¡åº¦: {bottleneck_analysis['analysis_confidence']:.2f}")
        print(f"  ç´§æ€¥è¡ŒåŠ¨æ•°: {bottleneck_analysis['analysis_summary']['immediate_action_required']}")
        
        # æµ‹è¯•3ï¼šèµ„æºåˆ†é…ä¼˜åŒ–
        print("\n--- æµ‹è¯•3: èµ„æºåˆ†é…ä¼˜åŒ– ---")
        current_allocation = {
            'cpu_cores': {'allocated': 8},
            'memory_gb': {'allocated': 16},
            'storage_tb': {'allocated': 2}
        }
        
        performance_requirements = {
            'cpu_cores': 10,
            'memory_gb': 20,
            'storage_tb': 1
        }
        
        resource_constraints = {
            'cpu_cores': 12,
            'memory_gb': 32,
            'storage_tb': 5
        }
        
        optimization_result = analyzer.optimize_resource_allocation(
            current_allocation, performance_requirements, resource_constraints,
            optimization_objective="balanced"
        )
        print(f"âœ“ èµ„æºåˆ†é…ä¼˜åŒ–å®Œæˆ")
        print(f"  ä¼˜åŒ–ç›®æ ‡: {optimization_result['optimization_objective']}")
        print(f"  ä¼˜åŒ–ç½®ä¿¡åº¦: {optimization_result['optimization_confidence']:.2f}")
        print(f"  å®æ–½å¤æ‚åº¦: {optimization_result['optimization_summary']['implementation_complexity']}")
        print(f"  é¢„æœŸæ€§èƒ½æå‡: {optimization_result['optimization_summary']['expected_performance_improvement']:.1f}%")
        print(f"  ä¼˜åŒ–é˜¶æ®µæ•°: {len(optimization_result['implementation_plan']['implementation_phases'])}")
        
        print("\nâœ“ æ‰€æœ‰ PerformanceAnalyzer æ–°åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"âœ— PerformanceAnalyzer æ–°åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ç­–ç•¥è¿ç§»ç³»ç»Ÿæ–°å¢åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    test_results = []
    
    # æµ‹è¯• TransferEvaluator æ–°åŠŸèƒ½
    test_results.append(("TransferEvaluator æ–°åŠŸèƒ½", test_transfer_evaluator_new_features()))
    
    # æµ‹è¯• PerformanceAnalyzer æ–°åŠŸèƒ½
    test_results.append(("PerformanceAnalyzer æ–°åŠŸèƒ½", test_performance_analyzer_new_features()))
    
    # æ€»ç»“æµ‹è¯•ç»“æœ
    print("\n" + "=" * 50)
    print("æ–°åŠŸèƒ½æµ‹è¯•æ€»ç»“:")
    print("=" * 50)
    
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»æµ‹è¯•æ•°: {total}")
    print(f"é€šè¿‡æµ‹è¯•: {passed}")
    print(f"å¤±è´¥æµ‹è¯•: {total - passed}")
    print(f"é€šè¿‡ç‡: {passed/total*100:.1f}%")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æ–°åŠŸèƒ½æµ‹è¯•éƒ½é€šè¿‡äº†ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæ–°åŠŸèƒ½æµ‹è¯•å¤±è´¥")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)