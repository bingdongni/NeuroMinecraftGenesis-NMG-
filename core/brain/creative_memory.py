"""
åˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿ - æ ¸å¿ƒåˆ›æ–°ç®—æ³•å®ç° (å‡çº§ç‰ˆ)

æœ¬æ¨¡å—å®ç°äº†åŸºäºæ‰©æ•£æ¨¡å‹å’Œç”Ÿæˆå¯¹æŠ—ç½‘ç»œçš„å…ˆè¿›åˆ›æ„è®°å¿†ç³»ç»Ÿï¼Œ
åŒ…å«æ–°é¢–æ€§æ£€æµ‹ã€è”æƒ³å˜å¼‚ã€ç»„åˆåˆ›æ–°ç­‰æ ¸å¿ƒç®—æ³•ï¼Œä¸ºAIç³»ç»Ÿæä¾›åˆ›é€ æ€§æ€ç»´èƒ½åŠ›ã€‚

å‡çº§åŠŸèƒ½ï¼š
1. æ‰©æ•£æ¨¡å‹ç”Ÿæˆæœºåˆ¶ - ç”¨äºåˆ›æ„å†…å®¹çš„ç”Ÿæˆå’Œç»†åŒ–
2. ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN) - ç”¨äºåˆ›æ„è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–
3. åˆ›æ„ç”Ÿæˆå’Œæ–°é¢–æ€§è¯„ä¼° - å¤šå±‚æ¬¡çš„æ–°é¢–æ€§æ£€æµ‹
4. å¤šæ¨¡æ€åˆ›æ„èåˆ - è·¨æ¨¡æ€çš„åˆ›æ„ç»„åˆ
5. åˆ›æ„è´¨é‡è¯„ä»·å’Œä¼˜åŒ– - åŸºäºGANçš„è‡ªåŠ¨ä¼˜åŒ–

ä½œè€…: AIåˆ›é€ åŠ›ç³»ç»Ÿ
åˆ›å»ºæ—¶é—´: 2025-11-13
ç‰ˆæœ¬: 2.0 (å‡çº§ç‰ˆ)
"""

import numpy as np
import random
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Tuple, Any, Optional, Union
from datetime import datetime, timedelta
from collections import defaultdict, deque
import math
import copy


# ==================== æ‰©æ•£æ¨¡å‹å®ç° ====================

class DiffusionModel:
    """æ‰©æ•£æ¨¡å‹ç”¨äºåˆ›æ„ç”Ÿæˆå’Œç»†åŒ–"""
    
    def __init__(self, feature_dim: int = 128, timesteps: int = 1000, device: str = 'cpu'):
        """
        åˆå§‹åŒ–æ‰©æ•£æ¨¡å‹
        
        Args:
            feature_dim: ç‰¹å¾å‘é‡ç»´åº¦
            timesteps: æ‰©æ•£æ—¶é—´æ­¥æ•°
            device: è®¡ç®—è®¾å¤‡ ('cpu' æˆ– 'cuda')
        """
        self.feature_dim = feature_dim
        self.timesteps = timesteps
        self.device = device
        self.model = None
        self.noise_schedule = np.linspace(0.001, 0.02, timesteps)
        self.initialize_model()
    
    def initialize_model(self):
        """åˆå§‹åŒ–æ‰©æ•£æ¨¡å‹ç½‘ç»œ"""
        class DiffusionUNet(nn.Module):
            def __init__(self, feature_dim, timesteps):
                super().__init__()
                self.feature_dim = feature_dim
                self.time_embed = nn.Embedding(timesteps, 64)
                self.net = nn.Sequential(
                    nn.Linear(feature_dim + 64, 256),
                    nn.ReLU(),
                    nn.Dropout(0.1),
                    nn.Linear(256, 256),
                    nn.ReLU(),
                    nn.Linear(256, feature_dim)
                )
            
            def forward(self, x, t):
                time_embed = self.time_embed(t)
                x_embed = torch.cat([x, time_embed], dim=-1)
                return self.net(x_embed)
        
        self.model = DiffusionUNet(self.feature_dim, self.timesteps).to(self.device)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        self.initialized = True
    
    def forward_diffusion(self, x0: torch.Tensor, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        å‰å‘æ‰©æ•£è¿‡ç¨‹ï¼šæ·»åŠ å™ªå£°
        
        Args:
            x0: åŸå§‹ç‰¹å¾
            t: æ—¶é—´æ­¥
            
        Returns:
            æ·»åŠ å™ªå£°çš„ç‰¹å¾å’Œå™ªå£°
        """
        noise = torch.randn_like(x0).to(self.device)
        alpha_t = self.noise_schedule[t]
        
        # æ·»åŠ å™ªå£°
        xt = torch.sqrt(alpha_t) * x0 + torch.sqrt(1 - alpha_t) * noise
        
        return xt, noise
    
    def denoise_step(self, xt: torch.Tensor, t: int) -> torch.Tensor:
        """
        å»å™ªæ­¥éª¤
        
        Args:
            xt: å½“å‰ç‰¹å¾
            t: å½“å‰æ—¶é—´æ­¥
            
        Returns:
            å»å™ªåçš„ç‰¹å¾
        """
        t_tensor = torch.tensor([t] * xt.shape[0]).to(self.device)
        predicted_noise = self.model(xt, t_tensor)
        
        # è®¡ç®—å»å™ªç‰¹å¾
        alpha_t = self.noise_schedule[t]
        alpha_t_prev = self.noise_schedule[t-1] if t > 0 else 0.001
        
        x0_pred = (xt - torch.sqrt(1 - alpha_t) * predicted_noise) / torch.sqrt(alpha_t)
        
        # DDPMé‡‡æ ·
        noise = torch.randn_like(xt).to(self.device) if t > 0 else 0
        xt_prev = torch.sqrt(alpha_t_prev) * x0_pred + torch.sqrt(1 - alpha_t_prev) * noise
        
        return xt_prev
    
    def generate_creative_content(self, batch_size: int = 1) -> np.ndarray:
        """
        ç”Ÿæˆåˆ›æ„å†…å®¹
        
        Args:
            batch_size: ç”Ÿæˆæ‰¹æ¬¡å¤§å°
            
        Returns:
            ç”Ÿæˆçš„åˆ›æ„ç‰¹å¾
        """
        self.model.eval()
        with torch.no_grad():
            # ä»çº¯å™ªå£°å¼€å§‹
            x = torch.randn(batch_size, self.feature_dim).to(self.device)
            
            # é€æ­¥å»å™ª
            for t in reversed(range(self.timesteps)):
                if t % 100 == 0:
                    print(f"  æ‰©æ•£æ¨¡å‹é‡‡æ ·è¿›åº¦: {t}/{self.timesteps}")
                x = self.denoise_step(x, t)
            
            # å½’ä¸€åŒ–
            x = torch.tanh(x)
        
        return x.cpu().numpy()
    
    def train_step(self, real_features: torch.Tensor) -> Dict[str, float]:
        """
        è®­ç»ƒæ‰©æ•£æ¨¡å‹
        
        Args:
            real_features: çœŸå®ç‰¹å¾æ•°æ®
            
        Returns:
            è®­ç»ƒæŸå¤±ä¿¡æ¯
        """
        self.model.train()
        
        # éšæœºæ—¶é—´æ­¥
        t = torch.randint(0, self.timesteps, (real_features.shape[0],)).to(self.device)
        
        # å‰å‘æ‰©æ•£
        xt, noise = self.forward_diffusion(real_features, t)
        
        # é¢„æµ‹å™ªå£°
        predicted_noise = self.model(xt, t)
        
        # è®¡ç®—æŸå¤±
        loss = nn.MSELoss()(predicted_noise, noise)
        
        # åå‘ä¼ æ’­
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
        
        return {'diffusion_loss': loss.item()}


# ==================== ç”Ÿæˆå¯¹æŠ—ç½‘ç»œå®ç° ====================

class CreativeGAN:
    """ç”¨äºåˆ›æ„è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ"""
    
    def __init__(self, feature_dim: int = 128, device: str = 'cpu'):
        """
        åˆå§‹åŒ–GAN
        
        Args:
            feature_dim: ç‰¹å¾ç»´åº¦
            device: è®¡ç®—è®¾å¤‡
        """
        self.feature_dim = feature_dim
        self.device = device
        
        self.generator = self._build_generator()
        self.discriminator = self._build_discriminator()
        
        self.gen_optimizer = optim.Adam(self.generator.parameters(), lr=0.0002)
        self.disc_optimizer = optim.Adam(self.discriminator.parameters(), lr=0.0002)
        
        self.criterion = nn.BCELoss()
        
        # è®­ç»ƒå†å²
        self.training_history = {
            'gen_losses': [],
            'disc_losses': [],
            'quality_scores': []
        }
    
    def _build_generator(self) -> nn.Module:
        """æ„å»ºç”Ÿæˆå™¨ç½‘ç»œ"""
        class Generator(nn.Module):
            def __init__(self, feature_dim):
                super().__init__()
                self.net = nn.Sequential(
                    nn.Linear(128, 256),
                    nn.ReLU(),
                    nn.BatchNorm1d(256),
                    nn.Dropout(0.3),
                    nn.Linear(256, 512),
                    nn.ReLU(),
                    nn.BatchNorm1d(512),
                    nn.Dropout(0.3),
                    nn.Linear(512, feature_dim),
                    nn.Tanh()
                )
            
            def forward(self, z):
                return self.net(z)
        
        return Generator(self.feature_dim).to(self.device)
    
    def _build_discriminator(self) -> nn.Module:
        """æ„å»ºåˆ¤åˆ«å™¨ç½‘ç»œ"""
        class Discriminator(nn.Module):
            def __init__(self, feature_dim):
                super().__init__()
                self.net = nn.Sequential(
                    nn.Linear(feature_dim, 512),
                    nn.LeakyReLU(0.2),
                    nn.Dropout(0.3),
                    nn.Linear(512, 256),
                    nn.LeakyReLU(0.2),
                    nn.Dropout(0.3),
                    nn.Linear(256, 1),
                    nn.Sigmoid()
                )
            
            def forward(self, x):
                return self.net(x)
        
        return Discriminator(self.feature_dim).to(self.device)
    
    def train_step(self, real_features: torch.Tensor, batch_size: int = 32) -> Dict[str, float]:
        """
        GANè®­ç»ƒæ­¥éª¤
        
        Args:
            real_features: çœŸå®ç‰¹å¾æ•°æ®
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            è®­ç»ƒæŸå¤±ä¿¡æ¯
        """
        self.generator.train()
        self.discriminator.train()
        
        # è®­ç»ƒåˆ¤åˆ«å™¨
        self.discriminator.zero_grad()
        
        # çœŸå®æ•°æ®
        real_labels = torch.ones(batch_size, 1).to(self.device)
        real_output = self.discriminator(real_features[:batch_size])
        real_loss = self.criterion(real_output, real_labels)
        
        # ç”Ÿæˆæ•°æ®
        noise = torch.randn(batch_size, 128).to(self.device)
        fake_features = self.generator(noise)
        fake_labels = torch.zeros(batch_size, 1).to(self.device)
        fake_output = self.discriminator(fake_features)
        fake_loss = self.criterion(fake_output, fake_labels)
        
        # æ€»åˆ¤åˆ«å™¨æŸå¤±
        disc_loss = (real_loss + fake_loss) / 2
        disc_loss.backward()
        self.disc_optimizer.step()
        
        # è®­ç»ƒç”Ÿæˆå™¨
        self.generator.zero_grad()
        
        # é‡æ–°ç”Ÿæˆæ•°æ®
        noise = torch.randn(batch_size, 128).to(self.device)
        fake_features = self.generator(noise)
        fake_output = self.discriminator(fake_features)
        
        # ç”Ÿæˆå™¨å¸Œæœ›åˆ¤åˆ«å™¨è®¤ä¸ºç”Ÿæˆæ•°æ®æ˜¯çœŸå®çš„
        gen_loss = self.criterion(fake_output, real_labels)
        gen_loss.backward()
        self.gen_optimizer.step()
        
        # è®°å½•è®­ç»ƒå†å²
        self.training_history['gen_losses'].append(gen_loss.item())
        self.training_history['disc_losses'].append(disc_loss.item())
        
        return {
            'generator_loss': gen_loss.item(),
            'discriminator_loss': disc_loss.item()
        }
    
    def generate_creative_features(self, num_samples: int = 1) -> np.ndarray:
        """
        ç”Ÿæˆåˆ›æ„ç‰¹å¾
        
        Args:
            num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
            
        Returns:
            ç”Ÿæˆçš„åˆ›æ„ç‰¹å¾
        """
        self.generator.eval()
        with torch.no_grad():
            noise = torch.randn(num_samples, 128).to(self.device)
            generated_features = self.generator(noise)
            # æ·»åŠ tanhæ¿€æ´»ç¡®ä¿èŒƒå›´åœ¨[-1, 1]
            generated_features = torch.tanh(generated_features)
        
        return generated_features.cpu().numpy()
    
    def evaluate_quality(self, features: np.ndarray) -> float:
        """
        è¯„ä¼°åˆ›æ„è´¨é‡
        
        Args:
            features: å¾…è¯„ä¼°çš„ç‰¹å¾
            
        Returns:
            è´¨é‡åˆ†æ•° [0, 1]
        """
        self.discriminator.eval()
        with torch.no_grad():
            features_tensor = torch.tensor(features).to(self.device)
            quality_score = self.discriminator(features_tensor).mean().item()
        
        return quality_score
    
    def get_training_metrics(self) -> Dict[str, Any]:
        """è·å–è®­ç»ƒæŒ‡æ ‡"""
        if not self.training_history['gen_losses']:
            return {'status': 'no_training_data'}
        
        return {
            'avg_generator_loss': np.mean(self.training_history['gen_losses'][-100:]),
            'avg_discriminator_loss': np.mean(self.training_history['disc_losses'][-100:]),
            'latest_quality_score': self.training_history['quality_scores'][-1] if self.training_history['quality_scores'] else 0.0,
            'training_steps': len(self.training_history['gen_losses'])
        }


# ==================== å¤šæ¨¡æ€åˆ›æ„èåˆå™¨ ====================

class MultimodalCreativeFusion:
    """å¤šæ¨¡æ€åˆ›æ„èåˆå™¨"""
    
    def __init__(self, modal_dims: Dict[str, int]):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€èåˆå™¨
        
        Args:
            modal_dims: å„æ¨¡æ€çš„ç»´åº¦å­—å…¸ {'text': 512, 'image': 1024, 'audio': 256}
        """
        self.modal_dims = modal_dims
        self.fusion_weights = {modal: 1.0 for modal in modal_dims.keys()}
        self.cross_modal_attention = {}
        self._initialize_attention()
    
    def _initialize_attention(self):
        """åˆå§‹åŒ–è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶"""
        for modal1 in self.modal_dims.keys():
            for modal2 in self.modal_dims.keys():
                if modal1 != modal2:
                    key = f"{modal1}_to_{modal2}"
                    self.cross_modal_attention[key] = CrossModalAttention(
                        self.modal_dims[modal1], 
                        self.modal_dims[modal2]
                    )
    
    def fuse_creative_concepts(self, modal_data: Dict[str, np.ndarray], 
                              creative_type: str = 'innovation') -> Dict[str, np.ndarray]:
        """
        èåˆå¤šæ¨¡æ€åˆ›æ„æ¦‚å¿µ
        
        Args:
            modal_data: å„æ¨¡æ€çš„æ•°æ® {'text': text_features, 'image': image_features}
            creative_type: åˆ›æ„ç±»å‹ ('innovation', 'imagination', 'combination')
            
        Returns:
            èåˆåçš„å¤šæ¨¡æ€ç‰¹å¾
        """
        fused_features = {}
        
        # 1. æ¨¡æ€å†…èåˆ
        intra_fused = self._intra_modal_fusion(modal_data, creative_type)
        
        # 2. è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆ
        inter_fused = self._inter_modal_attention(intra_fused)
        
        # 3. åˆ›æ„ç±»å‹ç‰¹å®šèåˆ
        creative_fused = self._creative_type_specific_fusion(inter_fused, creative_type)
        
        return creative_fused
    
    def _intra_modal_fusion(self, modal_data: Dict[str, np.ndarray], 
                           creative_type: str) -> Dict[str, np.ndarray]:
        """æ¨¡æ€å†…èåˆ"""
        fused = {}
        
        for modal, data in modal_data.items():
            if modal in self.modal_dims:
                # åº”ç”¨æ¨¡æ€ç‰¹å®šçš„å¤„ç†
                if len(data.shape) > 1:
                    # å¦‚æœæ˜¯å¤šå®ä¾‹ï¼Œå–å¹³å‡
                    fused[modal] = np.mean(data, axis=0)
                else:
                    fused[modal] = data
                
                # æ¨¡æ€ç‰¹å®šå¢å¼º
                fused[modal] = self._enhance_modal_features(fused[modal], modal, creative_type)
        
        return fused
    
    def _inter_modal_attention(self, modal_features: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """è·¨æ¨¡æ€æ³¨æ„åŠ›èåˆ"""
        enhanced_features = {}
        
        for target_modal in modal_features.keys():
            enhanced_features[target_modal] = modal_features[target_modal].copy()
            
            # èšåˆæ¥è‡ªå…¶ä»–æ¨¡æ€çš„ä¿¡æ¯
            attention_sum = np.zeros_like(modal_features[target_modal])
            attention_count = 0
            
            for source_modal, source_features in modal_features.items():
                if source_modal != target_modal:
                    attention_key = f"{target_modal}_to_{source_modal}"
                    if attention_key in self.cross_modal_attention:
                        attention_weights = self.cross_modal_attention[attention_key].compute_attention(
                            modal_features[target_modal], source_features
                        )
                        
                        # åº”ç”¨æ³¨æ„åŠ›æƒé‡
                        attended_features = source_features * attention_weights
                        attention_sum += attended_features
                        attention_count += 1
            
            # èåˆæ³¨æ„åŠ›ç»“æœ
            if attention_count > 0:
                attention_sum /= attention_count
                fusion_ratio = 0.3  # æ³¨æ„åŠ›èåˆæ¯”ä¾‹
                enhanced_features[target_modal] = (
                    (1 - fusion_ratio) * enhanced_features[target_modal] + 
                    fusion_ratio * attention_sum
                )
        
        return enhanced_features
    
    def _creative_type_specific_fusion(self, modal_features: Dict[str, np.ndarray], 
                                     creative_type: str) -> Dict[str, np.ndarray]:
        """åˆ›æ„ç±»å‹ç‰¹å®šèåˆ"""
        
        if creative_type == 'innovation':
            # åˆ›æ–°å‹ï¼šå¼ºè°ƒå·®å¼‚æ€§å’Œæ–°é¢–æ€§
            return self._innovation_fusion(modal_features)
        elif creative_type == 'imagination':
            # æƒ³è±¡å‹ï¼šå¼ºè°ƒè”æƒ³å’Œç»„åˆ
            return self._imagination_fusion(modal_features)
        elif creative_type == 'combination':
            # ç»„åˆå‹ï¼šå¼ºè°ƒååŒå’Œæ•´åˆ
            return self._combination_fusion(modal_features)
        else:
            return modal_features
    
    def _innovation_fusion(self, modal_features: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """åˆ›æ–°å‹èåˆç­–ç•¥"""
        # å¢å¼ºç‰¹å¾å·®å¼‚æ€§
        fused = {}
        feature_list = list(modal_features.values())
        
        if len(feature_list) > 1:
            # è®¡ç®—ç‰¹å¾é—´å·®å¼‚
            for i, (modal, features) in enumerate(modal_features.items()):
                # ä¸å…¶ä»–æ¨¡æ€çš„å·®å¼‚
                differences = []
                for j, other_features in enumerate(feature_list):
                    if i != j:
                        diff = np.linalg.norm(features - other_features)
                        differences.append(diff)
                
                # å¢åŠ æ–°é¢–æ€§æƒé‡
                novelty_weight = np.mean(differences) if differences else 0
                enhanced_features = features * (1 + novelty_weight * 0.1)
                fused[modal] = enhanced_features
        else:
            fused = modal_features
        
        return fused
    
    def _imagination_fusion(self, modal_features: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """æƒ³è±¡å‹èåˆç­–ç•¥"""
        # å¢å¼ºè”æƒ³æ€§
        fused = {}
        feature_array = np.array(list(modal_features.values()))
        
        # è®¡ç®—è”æƒ³å‘é‡ï¼ˆç‰¹å¾é—´çš„ä¸­é—´å€¼ï¼‰
        if len(feature_array) > 1:
            associative_vector = np.mean(feature_array, axis=0)
            
            for modal, features in modal_features.items():
                # å¢å¼ºè”æƒ³æ€§
                associative_enhancement = np.tanh((associative_vector - features) * 2)
                enhanced_features = features + associative_enhancement * 0.2
                fused[modal] = enhanced_features
        else:
            fused = modal_features
        
        return fused
    
    def _combination_fusion(self, modal_features: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:
        """ç»„åˆå‹èåˆç­–ç•¥"""
        # å¼ºè°ƒååŒæ€§
        fused = {}
        feature_list = list(modal_features.values())
        
        if len(feature_list) > 1:
            # è®¡ç®—ååŒå‘é‡
           ååŒ_vector = np.sum(feature_list, axis=0)
            
            for modal, features in modal_features.items():
                # ååŒå¢å¼º
                synergy_factor = np.dot(features, ååŒ_vector) / (np.linalg.norm(features) * np.linalg.norm(ååŒ_vector) + 1e-8)
                enhanced_features = features * (1 + synergy_factor * 0.15)
                fused[modal] = enhanced_features
        else:
            fused = modal_features
        
        return fused
    
    def _enhance_modal_features(self, features: np.ndarray, modal: str, creative_type: str) -> np.ndarray:
        """å¢å¼ºæ¨¡æ€ç‰¹å®šç‰¹å¾"""
        # æ¨¡æ€ç‰¹å®šå¢å¼ºé€»è¾‘
        if modal == 'text':
            # æ–‡æœ¬æ¨¡æ€ï¼šå¢å¼ºè¯­ä¹‰ä¸°å¯Œåº¦
            feature_variance = np.var(features)
            enhanced = features * (1 + feature_variance * 0.1)
        elif modal == 'image':
            # å›¾åƒæ¨¡æ€ï¼šå¢å¼ºç©ºé—´å¤šæ ·æ€§
            enhanced = features * (1 + np.random.normal(0, 0.05, len(features)))
        elif modal == 'audio':
            # éŸ³é¢‘æ¨¡æ€ï¼šå¢å¼ºé¢‘ç‡ç‰¹æ€§
            enhanced = np.tanh(features)  # ä½¿ç”¨tanhæ¿€æ´»å¢å¼ºåŠ¨æ€èŒƒå›´
        else:
            enhanced = features
        
        return enhanced


class CrossModalAttention:
    """è·¨æ¨¡æ€æ³¨æ„åŠ›æœºåˆ¶"""
    
    def __init__(self, query_dim: int, key_dim: int):
        self.query_dim = query_dim
        self.key_dim = key_dim
        self.attention_weights = None
    
    def compute_attention(self, query_features: np.ndarray, key_features: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—æ³¨æ„åŠ›æƒé‡
        
        Args:
            query_features: æŸ¥è¯¢ç‰¹å¾
            key_features: é”®ç‰¹å¾
            
        Returns:
            æ³¨æ„åŠ›æƒé‡
        """
        # ç®€åŒ–çš„æ³¨æ„åŠ›è®¡ç®—
        similarity = np.dot(query_features, key_features) / (
            np.linalg.norm(query_features) * np.linalg.norm(key_features) + 1e-8
        )
        
        # Softmaxæ¿€æ´»
        attention_weights = np.exp(similarity * 2) / (1 + np.exp(similarity * 2))
        
        return attention_weights


# ==================== ä¸»è¦çš„åˆ›æ„è®°å¿†ç³»ç»Ÿç±» ====================

class CreativeMemory:
    """
    åˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿæ ¸å¿ƒç±» (å‡çº§ç‰ˆ)
    
    å‡çº§åŠŸèƒ½ï¼š
    1. æ‰©æ•£æ¨¡å‹ç”Ÿæˆæœºåˆ¶ - ç”¨äºåˆ›æ„å†…å®¹çš„ç”Ÿæˆå’Œç»†åŒ–
    2. ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ(GAN) - ç”¨äºåˆ›æ„è´¨é‡è¯„ä¼°å’Œä¼˜åŒ–
    3. åˆ›æ„ç”Ÿæˆå’Œæ–°é¢–æ€§è¯„ä¼° - å¤šå±‚æ¬¡çš„æ–°é¢–æ€§æ£€æµ‹
    4. å¤šæ¨¡æ€åˆ›æ„èåˆ - è·¨æ¨¡æ€çš„åˆ›æ„ç»„åˆ
    5. åˆ›æ„è´¨é‡è¯„ä»·å’Œä¼˜åŒ– - åŸºäºGANçš„è‡ªåŠ¨ä¼˜åŒ–
    
    è¯¥ç³»ç»Ÿæ¨¡æ‹Ÿå¤§è„‘çš„åˆ›é€ æ€§æ€ç»´æœºåˆ¶ï¼Œé€šè¿‡å…ˆè¿›çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œ
    äº§ç”Ÿå…·æœ‰åˆ›æ–°æ€§ã€å¤šæ ·æ€§å’Œé«˜è´¨é‡çš„åˆ›æ„å†…å®¹ã€‚
    """
    
    def __init__(self, memory_capacity: int = 10000, novelty_threshold: float = 0.4, 
                 device: str = 'cpu', modal_dims: Optional[Dict[str, int]] = None):
        """
        åˆå§‹åŒ–åˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿ
        
        Args:
            memory_capacity: è®°å¿†å®¹é‡ä¸Šé™
            novelty_threshold: æ–°é¢–æ€§æ£€æµ‹é˜ˆå€¼
            device: è®¡ç®—è®¾å¤‡
            modal_dims: å¤šæ¨¡æ€ç»´åº¦é…ç½®
        """
        # åŸºç¡€å­˜å‚¨
        self.memories = []  # å­˜å‚¨æ‰€æœ‰è®°å¿†æ¡ç›®
        self.action_library = {}  # è¡Œä¸ºåŠ¨ä½œåº“
        self.novelty_memory = deque(maxlen=1000)  # æ–°é¢–æ€§è®°å¿†ç¼“å­˜
        
        # å‡çº§åŠŸèƒ½ç»„ä»¶
        self.diffusion_model = DiffusionModel(feature_dim=128, device=device)
        self.creative_gan = CreativeGAN(feature_dim=128, device=device)
        
        # å¤šæ¨¡æ€é…ç½®
        if modal_dims is None:
            modal_dims = {'text': 512, 'image': 1024, 'audio': 256, 'sensor': 128}
        self.modal_dims = modal_dims
        self.multimodal_fusion = MultimodalCreativeFusion(modal_dims)
        
        # ç³»ç»Ÿå‚æ•°
        self.memory_capacity = memory_capacity
        self.novelty_threshold = novelty_threshold
        self.mutation_threshold = 0.3  # è”æƒ³å˜å¼‚ç›¸ä¼¼åº¦é˜ˆå€¼
        self.device = device
        
        # åˆ›æ–°ç»Ÿè®¡
        self.innovation_stats = {
            'total_actions': 0,
            'innovative_actions': 0,
            'novel_behaviors': 0,
            'diffusion_generations': 0,
            'gan_generations': 0,
            'quality_optimizations': 0,
            'multimodal_fusions': 0,
            'start_time': datetime.now()
        }
        
        # è´¨é‡è¯„ä¼°å†å²
        self.quality_history = deque(maxlen=500)
        self.creative_quality_scores = []
        
        # è¡Œä¸ºé¢‘ç‡è·Ÿè¸ª
        self.behavior_frequency = defaultdict(int)
        self.hourly_novel_behaviors = deque(maxlen=24)
        
        # è®°å¿†ç‰¹å¾å‘é‡ç»´åº¦
        self.feature_dim = 128
        
        # è®­ç»ƒè®¡æ•°å™¨
        self.training_step = 0
        
        print(f"ğŸ¨ åˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿå‡çº§ç‰ˆåˆå§‹åŒ–å®Œæˆ")
        print(f"   æ‰©æ•£æ¨¡å‹: âœ… å·²å¯ç”¨")
        print(f"   GANç½‘ç»œ: âœ… å·²å¯ç”¨")
        print(f"   å¤šæ¨¡æ€èåˆ: âœ… å·²å¯ç”¨")
        print(f"   è®°å¿†å®¹é‡: {memory_capacity}")
        print(f"   æ–°é¢–æ€§é˜ˆå€¼: {novelty_threshold}")
        print(f"   è®¡ç®—è®¾å¤‡: {device}")
    
    def enhanced_novelty_detection(self, current_perception: np.ndarray, 
                                 modal_type: str = 'sensor') -> Dict[str, Any]:
        """
        å¢å¼ºç‰ˆæ–°é¢–æ€§æ£€æµ‹ç®—æ³•
        
        ä½¿ç”¨å¤šå±‚æ¬¡æ£€æµ‹æœºåˆ¶ï¼š
        1. åŸºç¡€ç›¸ä¼¼åº¦æ£€æµ‹
        2. æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯¹æ¯”
        3. GANè´¨é‡è¯„ä¼°
        
        Args:
            current_perception: å½“å‰æ„ŸçŸ¥ç‰¹å¾å‘é‡
            modal_type: æ¨¡æ€ç±»å‹ ('text', 'image', 'audio', 'sensor')
            
        Returns:
            Dict containing enhanced novelty assessment
        """
        # 1. åŸºç¡€æ–°é¢–æ€§æ£€æµ‹
        basic_novelty = self._basic_novelty_detection(current_perception)
        
        # 2. æ‰©æ•£æ¨¡å‹ç”Ÿæˆå¯¹æ¯”
        diffusion_novelty = self._diffusion_based_novelty(current_perception)
        
        # 3. GANè´¨é‡è¯„ä¼°
        gan_quality = self._gan_based_quality_assessment(current_perception)
        
        # 4. å¤šæ¨¡æ€èåˆæ£€æµ‹
        multimodal_novelty = self._multimodal_novelty_detection(current_perception, modal_type)
        
        # 5. ç»¼åˆæ–°é¢–æ€§è¯„åˆ†
        novelty_score = self._compute_enhanced_novelty_score(
            basic_novelty, diffusion_novelty, gan_quality, multimodal_novelty
        )
        
        # 6. å¤šå·´èƒºè°ƒåˆ¶
        dopamine_level = self._compute_enhanced_dopamine_level(novelty_score, gan_quality)
        
        result = {
            'novelty_score': novelty_score,
            'dopamine_level': dopamine_level,
            'is_highly_novel': novelty_score > self.novelty_threshold,
            'quality_score': gan_quality,
            'modal_type': modal_type,
            'component_scores': {
                'basic': basic_novelty,
                'diffusion': diffusion_novelty,
                'gan_quality': gan_quality,
                'multimodal': multimodal_novelty
            }
        }
        
        # æ›´æ–°æ–°é¢–æ€§è®°å¿†ç¼“å­˜
        self.novelty_memory.append({
            'timestamp': datetime.now(),
            'novelty_score': novelty_score,
            'dopamine_level': dopamine_level,
            'is_highly_novel': result['is_highly_novel'],
            'quality_score': gan_quality
        })
        
        return result
    
    def _basic_novelty_detection(self, current_perception: np.ndarray) -> Dict[str, Any]:
        """åŸºç¡€æ–°é¢–æ€§æ£€æµ‹"""
        if len(self.memories) == 0:
            return {'novelty_score': 1.0, 'max_similarity': 0.0}
        
        similarities = []
        for memory in self.memories:
            similarity = self._cosine_similarity(current_perception, memory['features'])
            similarities.append(similarity)
        
        max_similarity = max(similarities) if similarities else 0.0
        novelty_score = 1.0 - max_similarity
        
        return {'novelty_score': novelty_score, 'max_similarity': max_similarity}
    
    def _diffusion_based_novelty(self, current_perception: np.ndarray) -> Dict[str, Any]:
        """åŸºäºæ‰©æ•£æ¨¡å‹çš„æ–°é¢–æ€§æ£€æµ‹"""
        try:
            # ç”Ÿæˆæ‰©æ•£æ¨¡å‹æ ·æœ¬è¿›è¡Œå¯¹æ¯”
            generated_samples = self.diffusion_model.generate_creative_content(batch_size=5)
            
            # è®¡ç®—ä¸ç”Ÿæˆæ ·æœ¬çš„å·®å¼‚
            diffusion_distances = []
            for sample in generated_samples:
                distance = np.linalg.norm(current_perception - sample)
                diffusion_distances.append(distance)
            
            # è·ç¦»è¶Šå°ï¼Œæ–°é¢–æ€§è¶Šé«˜
            avg_distance = np.mean(diffusion_distances)
            max_possible_distance = np.sqrt(2 * len(current_perception))  # ç†è®ºæœ€å¤§è·ç¦»
            
            diffusion_novelty = min(avg_distance / max_possible_distance, 1.0)
            
            return {
                'novelty_score': diffusion_novelty,
                'avg_distance': avg_distance,
                'generated_samples': len(generated_samples)
            }
        except Exception as e:
            print(f"æ‰©æ•£æ¨¡å‹æ–°é¢–æ€§æ£€æµ‹å¤±è´¥: {e}")
            return {'novelty_score': 0.5, 'avg_distance': 0.5, 'generated_samples': 0}
    
    def _gan_based_quality_assessment(self, current_perception: np.ndarray) -> float:
        """åŸºäºGANçš„è´¨é‡è¯„ä¼°"""
        try:
            # å°†æ„ŸçŸ¥è½¬æ¢ä¸ºGANå¯è¯„ä¼°çš„æ ¼å¼
            if len(current_perception) != 128:
                # è°ƒæ•´ç»´åº¦
                if len(current_perception) < 128:
                    padded = np.pad(current_perception, (0, 128 - len(current_perception)))
                    gan_input = padded
                else:
                    gan_input = current_perception[:128]
            else:
                gan_input = current_perception
            
            # ä½¿ç”¨åˆ¤åˆ«å™¨è¯„ä¼°è´¨é‡
            quality_score = self.creative_gan.evaluate_quality(gan_input.reshape(1, -1))
            
            # æ›´æ–°è´¨é‡å†å²
            self.quality_history.append({
                'timestamp': datetime.now(),
                'quality_score': quality_score,
                'perception_norm': np.linalg.norm(current_perception)
            })
            
            return float(quality_score)
        except Exception as e:
            print(f"GANè´¨é‡è¯„ä¼°å¤±è´¥: {e}")
            return 0.5
    
    def _multimodal_novelty_detection(self, current_perception: np.ndarray, modal_type: str) -> Dict[str, Any]:
        """å¤šæ¨¡æ€æ–°é¢–æ€§æ£€æµ‹"""
        try:
            # åˆ›å»ºæ¨¡æ€ç‰¹å®šè¡¨ç¤º
            modal_data = {modal_type: current_perception}
            
            # ä½¿ç”¨å¤šæ¨¡æ€èåˆå™¨è¿›è¡Œæ–°é¢–æ€§æ£€æµ‹
            if len(self.memories) > 0:
                # ä»è®°å¿†ä¸­æå–ç›¸åŒæ¨¡æ€çš„æ•°æ®
                same_modal_memories = [
                    m for m in self.memories 
                    if m.get('modal_type') == modal_type
                ]
                
                if same_modal_memories:
                    memory_features = np.array([m['features'] for m in same_modal_memories[-10:]])
                    modal_data['memory_reference'] = np.mean(memory_features, axis=0)
                    
                    # è®¡ç®—å¤šæ¨¡æ€æ–°é¢–æ€§
                    reference_features = modal_data['memory_reference']
                    distance = np.linalg.norm(current_perception - reference_features)
                    max_distance = np.sqrt(2 * len(current_perception))
                    multimodal_novelty = min(distance / max_distance, 1.0)
                else:
                    multimodal_novelty = 0.8  # é»˜è®¤æ–°é¢–æ€§
            else:
                multimodal_novelty = 1.0  # å®Œå…¨æ–°é¢–
            
            return {
                'novelty_score': multimodal_novelty,
                'modal_type': modal_type,
                'memory_references': len([m for m in self.memories if m.get('modal_type') == modal_type])
            }
        except Exception as e:
            print(f"å¤šæ¨¡æ€æ–°é¢–æ€§æ£€æµ‹å¤±è´¥: {e}")
            return {'novelty_score': 0.5, 'modal_type': modal_type, 'memory_references': 0}
    
    def _compute_enhanced_novelty_score(self, basic: Dict, diffusion: Dict, 
                                      gan_quality: float, multimodal: Dict) -> float:
        """è®¡ç®—å¢å¼ºç‰ˆæ–°é¢–æ€§åˆ†æ•°"""
        # æƒé‡é…ç½®
        weights = {
            'basic': 0.3,
            'diffusion': 0.3,
            'quality_penalty': 0.2,  # è´¨é‡é«˜æ—¶æ–°é¢–æ€§é™ä½
            'multimodal': 0.2
        }
        
        # åŸºç¡€æ–°é¢–æ€§
        basic_score = basic['novelty_score']
        
        # æ‰©æ•£æ–°é¢–æ€§
        diffusion_score = diffusion['novelty_score']
        
        # è´¨é‡æƒ©ç½šï¼ˆé«˜è´¨é‡æ ·æœ¬æ–°é¢–æ€§ç¨é™ä½ï¼‰
        quality_score = gan_quality
        quality_penalty = quality_score * 0.1  # è´¨é‡è¶Šé«˜ï¼Œæ–°é¢–æ€§ç•¥å¾®é™ä½
        
        # å¤šæ¨¡æ€æ–°é¢–æ€§
        multimodal_score = multimodal['novelty_score']
        
        # ç»¼åˆè¯„åˆ†
        enhanced_score = (
            weights['basic'] * basic_score +
            weights['diffusion'] * diffusion_score +
            weights['quality_penalty'] * (1 - quality_penalty) +
            weights['multimodal'] * multimodal_score
        )
        
        return min(enhanced_score, 1.0)
    
    def _compute_enhanced_dopamine_level(self, novelty_score: float, quality_score: float) -> float:
        """è®¡ç®—å¢å¼ºç‰ˆå¤šå·´èƒºæ°´å¹³"""
        # åŸºç¡€å¤šå·´èƒºï¼ˆæ–°é¢–æ€§é©±åŠ¨ï¼‰
        base_dopamine = novelty_score * 0.8
        
        # è´¨é‡å¥–åŠ±ï¼ˆé«˜è´¨é‡åˆ›æ„é¢å¤–å¥–åŠ±ï¼‰
        quality_reward = quality_score * 0.3
        
        # å¤šå·´èƒºæ€»å’Œ
        total_dopamine = base_dopamine + quality_reward
        
        # é™åˆ¶èŒƒå›´
        return min(total_dopamine, 2.0)
    
    def generate_creative_content_advanced(self, num_samples: int = 1, 
                                         generation_method: str = 'diffusion',
                                         quality_threshold: float = 0.7) -> List[Dict[str, Any]]:
        """
        é«˜çº§åˆ›æ„å†…å®¹ç”Ÿæˆ
        
        Args:
            num_samples: ç”Ÿæˆæ ·æœ¬æ•°é‡
            generation_method: ç”Ÿæˆæ–¹æ³• ('diffusion', 'gan', 'hybrid')
            quality_threshold: è´¨é‡é˜ˆå€¼
            
        Returns:
            ç”Ÿæˆçš„åˆ›æ„å†…å®¹åˆ—è¡¨
        """
        generated_samples = []
        attempts = 0
        max_attempts = num_samples * 5  # æœ€å¤šå°è¯•æ¬¡æ•°
        
        while len(generated_samples) < num_samples and attempts < max_attempts:
            attempts += 1
            
            if generation_method == 'diffusion':
                features = self.diffusion_model.generate_creative_content(1)[0]
                method = 'diffusion'
            elif generation_method == 'gan':
                features = self.creative_gan.generate_creative_features(1)[0]
                method = 'gan'
            else:  # hybrid
                # æ··åˆç”Ÿæˆï¼šGANç”Ÿæˆ + æ‰©æ•£æ¨¡å‹ç»†åŒ–
                gan_features = self.creative_gan.generate_creative_features(1)[0]
                diffusion_features = self.diffusion_model.generate_creative_content(1)[0]
                features = (gan_features + diffusion_features) / 2
                method = 'hybrid'
            
            # è´¨é‡è¯„ä¼°
            quality_score = self.creative_gan.evaluate_quality(features.reshape(1, -1))
            
            # å¦‚æœè´¨é‡è¾¾åˆ°é˜ˆå€¼ï¼Œä¿ç•™æ ·æœ¬
            if quality_score >= quality_threshold:
                sample = {
                    'features': features,
                    'quality_score': quality_score,
                    'generation_method': method,
                    'timestamp': datetime.now(),
                    'novelty_assessment': self._basic_novelty_detection(features)
                }
                generated_samples.append(sample)
                
                # æ›´æ–°ç»Ÿè®¡
                self.innovation_stats[f'{method}_generations'] += 1
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(generated_samples)} ä¸ªé«˜è´¨é‡åˆ›æ„æ ·æœ¬")
        print(f"   ç”Ÿæˆæ–¹æ³•: {generation_method}")
        print(f"   å°è¯•æ¬¡æ•°: {attempts}")
        print(f"   æˆåŠŸç‡: {len(generated_samples)/attempts:.1%}")
        
        return generated_samples
    
    def advanced_associative_mutation(self, current_features: np.ndarray, 
                                    dopamine_level: float, 
                                    mutation_type: str = 'diffusion_enhanced') -> np.ndarray:
        """
        é«˜çº§è”æƒ³å˜å¼‚ç®—æ³•
        
        Args:
            current_features: å½“å‰ç‰¹å¾å‘é‡
            dopamine_level: å¤šå·´èƒºæ°´å¹³
            mutation_type: å˜å¼‚ç±»å‹ ('basic', 'diffusion_enhanced', 'gan_optimized', 'multimodal')
            
        Returns:
            å˜å¼‚åçš„æ–°ç‰¹å¾å‘é‡
        """
        if mutation_type == 'basic':
            # åŸºç¡€å˜å¼‚
            return self._basic_associative_mutation(current_features, dopamine_level)
        elif mutation_type == 'diffusion_enhanced':
            # æ‰©æ•£æ¨¡å‹å¢å¼ºå˜å¼‚
            return self._diffusion_enhanced_mutation(current_features, dopamine_level)
        elif mutation_type == 'gan_optimized':
            # GANä¼˜åŒ–å˜å¼‚
            return self._gan_optimized_mutation(current_features, dopamine_level)
        elif mutation_type == 'multimodal':
            # å¤šæ¨¡æ€å˜å¼‚
            return self._multimodal_mutation(current_features, dopamine_level)
        else:
            # é»˜è®¤ä½¿ç”¨æ‰©æ•£å¢å¼º
            return self._diffusion_enhanced_mutation(current_features, dopamine_level)
    
    def _diffusion_enhanced_mutation(self, current_features: np.ndarray, dopamine_level: float) -> np.ndarray:
        """æ‰©æ•£æ¨¡å‹å¢å¼ºå˜å¼‚"""
        try:
            # ç”Ÿæˆæ‰©æ•£æ¨¡å‹æ ·æœ¬
            diffusion_samples = self.diffusion_model.generate_creative_content(batch_size=3)
            
            # é€‰æ‹©æœ€ç›¸ä¼¼çš„æ ·æœ¬ä½œä¸ºå˜å¼‚åŸºç¡€
            similarities = []
            for sample in diffusion_samples:
                similarity = self._cosine_similarity(current_features, sample)
                similarities.append(similarity)
            
            # é€‰æ‹©ç›¸ä¼¼åº¦é€‚ä¸­çš„æ ·æœ¬ï¼ˆæ—¢ç›¸ä¼¼åˆæœ‰å·®å¼‚ï¼‰
            target_similarity = 0.3 + (dopamine_level * 0.2)  # å¤šå·´èƒºè¶Šé«˜ï¼Œå®¹å¿å·®å¼‚è¶Šå¤§
            best_idx = np.argmin([abs(sim - target_similarity) for sim in similarities])
            
            base_sample = diffusion_samples[best_idx]
            
            # åŸºäºå¤šå·´èƒºæ°´å¹³çš„å˜å¼‚å¼ºåº¦
            mutation_strength = min(dopamine_level / 2.0, 1.0)
            
            # æ‰§è¡Œå˜å¼‚
            mutated_features = (
                current_features * (1 - mutation_strength * 0.5) + 
                base_sample * (mutation_strength * 0.5)
            )
            
            # æ·»åŠ å™ªå£°
            noise_scale = mutation_strength * 0.1
            noise = np.random.normal(0, noise_scale, len(mutated_features))
            mutated_features += noise
            
            # å½’ä¸€åŒ–
            mutated_features = np.clip(mutated_features, -1, 1)
            
            return mutated_features
            
        except Exception as e:
            print(f"æ‰©æ•£å¢å¼ºå˜å¼‚å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å˜å¼‚: {e}")
            return self._basic_associative_mutation(current_features, dopamine_level)
    
    def _gan_optimized_mutation(self, current_features: np.ndarray, dopamine_level: float) -> np.ndarray:
        """GANä¼˜åŒ–å˜å¼‚"""
        try:
            # ç”Ÿæˆå¤šä¸ªGANæ ·æœ¬
            gan_samples = self.creative_gan.generate_creative_features(num_samples=5)
            
            # é€‰æ‹©è´¨é‡æœ€é«˜ä¸”æœ‰ä¸€å®šæ–°é¢–æ€§çš„æ ·æœ¬
            best_sample = None
            best_score = -1
            
            for sample in gan_samples:
                quality = self.creative_gan.evaluate_quality(sample.reshape(1, -1))
                novelty = 1 - self._cosine_similarity(current_features, sample)
                
                # ç»¼åˆè¯„åˆ†ï¼šè´¨é‡ + æ–°é¢–æ€§
                composite_score = quality * 0.7 + novelty * 0.3
                
                if composite_score > best_score:
                    best_score = composite_score
                    best_sample = sample
            
            if best_sample is not None:
                # åŸºäºå¤šå·´èƒºæ°´å¹³å†³å®šèåˆç¨‹åº¦
                fusion_ratio = min(dopamine_level / 2.0, 0.8)
                
                mutated_features = (
                    current_features * (1 - fusion_ratio) + 
                    best_sample * fusion_ratio
                )
                
                return mutated_features
            else:
                return current_features.copy()
                
        except Exception as e:
            print(f"GANä¼˜åŒ–å˜å¼‚å¤±è´¥: {e}")
            return current_features.copy()
    
    def _multimodal_mutation(self, current_features: np.ndarray, dopamine_level: float) -> np.ndarray:
        """å¤šæ¨¡æ€å˜å¼‚"""
        try:
            # æ¨¡æ‹Ÿå¤šæ¨¡æ€è¾“å…¥
            modal_data = {
                'sensor': current_features,
                'text': self.creative_gan.generate_creative_features(1)[0][:self.modal_dims['text']],
                'image': self.creative_gan.generate_creative_features(1)[0][:self.modal_dims['image']]
            }
            
            # ä½¿ç”¨å¤šæ¨¡æ€èåˆå™¨è¿›è¡Œå˜å¼‚
            fused_features_dict = self.multimodal_fusion.fuse_creative_concepts(
                modal_data, 
                creative_type='imagination'
            )
            
            # æå–èåˆåçš„ä¼ æ„Ÿå™¨æ¨¡æ€ç‰¹å¾
            if 'sensor' in fused_features_dict:
                sensor_fused = fused_features_dict['sensor']
                
                # åŸºäºå¤šå·´èƒºæ°´å¹³è°ƒæ•´å˜å¼‚å¼ºåº¦
                mutation_strength = min(dopamine_level / 2.0, 1.0)
                
                mutated_features = (
                    current_features * (1 - mutation_strength * 0.3) + 
                    sensor_fused * (mutation_strength * 0.7)
                )
                
                return mutated_features
            else:
                return current_features.copy()
                
        except Exception as e:
            print(f"å¤šæ¨¡æ€å˜å¼‚å¤±è´¥: {e}")
            return current_features.copy()
    
    def _basic_associative_mutation(self, current_features: np.ndarray, dopamine_level: float) -> np.ndarray:
        """åŸºç¡€è”æƒ³å˜å¼‚ï¼ˆä¿ç•™åŸæœ‰å®ç°ï¼‰"""
        if len(self.memories) < 2:
            return current_features.copy()
        
        # ç­›é€‰è¿œè·ç¦»è®°å¿†
        distant_memories = []
        for memory in self.memories:
            similarity = self._cosine_similarity(current_features, memory['features'])
            if similarity < self.mutation_threshold:
                distant_memories.append((memory, similarity))
        
        if not distant_memories:
            return current_features.copy()
        
        # æ ¹æ®å¤šå·´èƒºæ°´å¹³å†³å®šå˜å¼‚å¼ºåº¦
        mutation_intensity = min(dopamine_level / 2.0, 1.0)
        num_selections = min(int(1 + mutation_intensity * 2), len(distant_memories))
        selected_memories = random.sample(distant_memories, min(num_selections, len(distant_memories)))
        
        # æ‰§è¡Œå˜å¼‚
        mutated_features = current_features.copy()
        
        for memory, similarity in selected_memories:
            fusion_weight = (1.0 - similarity) * mutation_intensity * 0.3
            memory_features = memory['features']
            mutated_features = mutated_features * (1 - fusion_weight) + memory_features * fusion_weight
            
            noise_scale = fusion_weight * 0.1
            noise = np.random.normal(0, noise_scale, len(mutated_features))
            mutated_features += noise
        
        mutated_features = np.clip(mutated_features, -1, 1)
        return mutated_features
    
    def train_creative_models(self, training_data: np.ndarray, epochs: int = 10) -> Dict[str, Any]:
        """
        è®­ç»ƒåˆ›æ„ç”Ÿæˆæ¨¡å‹
        
        Args:
            training_data: è®­ç»ƒæ•°æ®
            epochs: è®­ç»ƒè½®æ•°
            
        Returns:
            è®­ç»ƒç»“æœæ‘˜è¦
        """
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒåˆ›æ„ç”Ÿæˆæ¨¡å‹...")
        print(f"   è®­ç»ƒæ•°æ®å¤§å°: {training_data.shape}")
        print(f"   è®­ç»ƒè½®æ•°: {epochs}")
        
        training_results = {
            'diffusion_losses': [],
            'gan_losses': [],
            'quality_improvements': [],
            'training_time': []
        }
        
        # è½¬æ¢æ•°æ®æ ¼å¼
        if isinstance(training_data, np.ndarray):
            training_tensor = torch.tensor(training_data, dtype=torch.float32).to(self.device)
        else:
            training_tensor = training_data.to(self.device)
        
        for epoch in range(epochs):
            epoch_start = datetime.now()
            
            # è®­ç»ƒæ‰©æ•£æ¨¡å‹
            if len(training_tensor) > 0:
                # éšæœºé‡‡æ ·æ‰¹æ¬¡
                batch_size = min(32, len(training_tensor))
                indices = torch.randperm(len(training_tensor))[:batch_size]
                batch_data = training_tensor[indices]
                
                diffusion_loss_dict = self.diffusion_model.train_step(batch_data)
                training_results['diffusion_losses'].append(diffusion_loss_dict['diffusion_loss'])
            
            # è®­ç»ƒGAN
            if len(training_tensor) > 0:
                gan_loss_dict = self.creative_gan.train_step(training_tensor[:batch_size])
                training_results['gan_losses'].append(gan_loss_dict)
            
            # è¯„ä¼°è´¨é‡æ”¹è¿›
            if len(training_tensor) > 0:
                sample_quality = []
                for i in range(min(10, len(training_tensor))):
                    quality = self.creative_gan.evaluate_quality(
                        training_tensor[i].cpu().numpy().reshape(1, -1)
                    )
                    sample_quality.append(quality)
                
                avg_quality = np.mean(sample_quality)
                training_results['quality_improvements'].append(avg_quality)
            
            epoch_time = (datetime.now() - epoch_start).total_seconds()
            training_results['training_time'].append(epoch_time)
            
            self.training_step += 1
            
            if epoch % 5 == 0 or epoch == epochs - 1:
                print(f"   Epoch {epoch+1}/{epochs} å®Œæˆ")
                print(f"   æ‰©æ•£æ¨¡å‹æŸå¤±: {training_results['diffusion_losses'][-1]:.4f}")
                print(f"   GANç”Ÿæˆå™¨æŸå¤±: {training_results['gan_losses'][-1]['generator_loss']:.4f}")
                print(f"   GANåˆ¤åˆ«å™¨æŸå¤±: {training_results['gan_losses'][-1]['discriminator_loss']:.4f}")
                print(f"   å¹³å‡è´¨é‡åˆ†æ•°: {training_results['quality_improvements'][-1]:.3f}")
        
        print("âœ… åˆ›æ„æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
        
        return {
            'total_epochs': epochs,
            'final_diffusion_loss': np.mean(training_results['diffusion_losses'][-5:]),
            'final_gan_generator_loss': np.mean([l['generator_loss'] for l in training_results['gan_losses'][-5:]]),
            'final_quality_score': np.mean(training_results['quality_improvements'][-5:]),
            'training_results': training_results
        }
    
    def create_multimodal_creative_concept(self, concept_description: str, 
                                         modal_inputs: Dict[str, np.ndarray]) -> Dict[str, Any]:
        """
        åˆ›å»ºå¤šæ¨¡æ€åˆ›æ„æ¦‚å¿µ
        
        Args:
            concept_description: æ¦‚å¿µæè¿°
            modal_inputs: å„æ¨¡æ€è¾“å…¥æ•°æ®
            
        Returns:
            å¤šæ¨¡æ€åˆ›æ„æ¦‚å¿µ
        """
        print(f"ğŸ¨ åˆ›å»ºå¤šæ¨¡æ€åˆ›æ„æ¦‚å¿µ: {concept_description}")
        
        # 1. å¤šæ¨¡æ€æ•°æ®é¢„å¤„ç†
        processed_modal_data = {}
        for modal, data in modal_inputs.items():
            if modal in self.modal_dims:
                # è°ƒæ•´ç»´åº¦
                if len(data) != self.modal_dims[modal]:
                    if len(data) < self.modal_dims[modal]:
                        padded = np.pad(data, (0, self.modal_dims[modal] - len(data)))
                        processed_modal_data[modal] = padded
                    else:
                        processed_modal_data[modal] = data[:self.modal_dims[modal]]
                else:
                    processed_modal_data[modal] = data
        
        # 2. å¤šæ¨¡æ€èåˆ
        fused_concept = self.multimodal_fusion.fuse_creative_concepts(
            processed_modal_data, 
            creative_type='innovation'
        )
        
        # 3. ç”Ÿæˆåˆ›æ„å†…å®¹
        creative_samples = self.generate_creative_content_advanced(
            num_samples=3, 
            generation_method='hybrid',
            quality_threshold=0.6
        )
        
        # 4. è´¨é‡è¯„ä¼°
        concept_quality_scores = []
        for modal, features in fused_concept.items():
            quality = self.creative_gan.evaluate_quality(features.reshape(1, -1))
            concept_quality_scores.append(quality)
        
        overall_quality = np.mean(concept_quality_scores)
        
        # 5. åˆ›å»ºå®Œæ•´æ¦‚å¿µ
        creative_concept = {
            'description': concept_description,
            'modal_features': fused_concept,
            'generated_samples': creative_samples,
            'quality_score': overall_quality,
            'modal_contributions': {
                modal: self._compute_modal_contribution(features, concept_description)
                for modal, features in fused_concept.items()
            },
            'creation_timestamp': datetime.now(),
            'innovation_potential': self._assess_innovation_potential(fused_concept, concept_description)
        }
        
        # æ›´æ–°ç»Ÿè®¡
        self.innovation_stats['multimodal_fusions'] += 1
        
        print(f"âœ… å¤šæ¨¡æ€åˆ›æ„æ¦‚å¿µåˆ›å»ºå®Œæˆ")
        print(f"   å‚ä¸æ¨¡æ€: {list(fused_concept.keys())}")
        print(f"   ç»¼åˆè´¨é‡åˆ†æ•°: {overall_quality:.3f}")
        print(f"   åˆ›æ–°æ½œåŠ›: {creative_concept['innovation_potential']:.3f}")
        
        return creative_concept
    
    def _compute_modal_contribution(self, features: np.ndarray, concept_description: str) -> Dict[str, Any]:
        """è®¡ç®—æ¨¡æ€è´¡çŒ®åº¦"""
        # ç‰¹å¾ç»Ÿè®¡
        feature_variance = np.var(features)
        feature_entropy = self._compute_feature_entropy(features)
        feature_magnitude = np.linalg.norm(features)
        
        # æ¨¡æ€ç‰¹å¼‚æ€§åˆ†æ
        uniqueness_score = min(feature_variance * 2, 1.0)
        diversity_score = min(feature_entropy / 10.0, 1.0)  # å‡è®¾æœ€å¤§ç†µä¸º10
        
        # ç»¼åˆè´¡çŒ®åº¦
        contribution_score = (uniqueness_score * 0.4 + diversity_score * 0.6) * \
                           (1 + feature_magnitude / 10.0)  # å¹…åº¦å› å­
        
        return {
            'uniqueness': uniqueness_score,
            'diversity': diversity_score,
            'magnitude': feature_magnitude,
            'contribution_score': min(contribution_score, 1.0),
            'feature_stats': {
                'variance': feature_variance,
                'entropy': feature_entropy,
                'mean': np.mean(features),
                'std': np.std(features)
            }
        }
    
    def _compute_feature_entropy(self, features: np.ndarray) -> float:
        """è®¡ç®—ç‰¹å¾ç†µ"""
        # ç®€åŒ–çš„ç†µè®¡ç®—
        normalized_features = (features - np.min(features)) / (np.max(features) - np.min(features) + 1e-8)
        
        # åˆ†æ¡¶è®¡ç®—
        bins = np.linspace(0, 1, 11)
        hist, _ = np.histogram(normalized_features, bins=bins)
        
        # è®¡ç®—ç†µ
        hist = hist + 1e-8  # é¿å…log(0)
        probabilities = hist / np.sum(hist)
        entropy = -np.sum(probabilities * np.log2(probabilities))
        
        return entropy
    
    def _assess_innovation_potential(self, fused_features: Dict[str, np.ndarray], 
                                   concept_description: str) -> float:
        """è¯„ä¼°åˆ›æ–°æ½œåŠ›"""
        # åŸºäºç‰¹å¾å¤šæ ·æ€§å’Œæ–°é¢–æ€§çš„åˆ›æ–°æ½œåŠ›è¯„ä¼°
        feature_vectors = list(fused_features.values())
        
        if len(feature_vectors) < 2:
            return 0.7  # å•æ¨¡æ€é»˜è®¤æ½œåŠ›
        
        # è®¡ç®—ç‰¹å¾é—´è·ç¦»
        distances = []
        for i in range(len(feature_vectors)):
            for j in range(i+1, len(feature_vectors)):
                distance = np.linalg.norm(feature_vectors[i] - feature_vectors[j])
                distances.append(distance)
        
        # åˆ›æ–°æ½œåŠ› = å¹³å‡è·ç¦» + ç‰¹å¾ç†µ
        avg_distance = np.mean(distances) if distances else 0.5
        
        # ç»„åˆå¤šæ ·æ€§
        entropy_scores = []
        for features in feature_vectors:
            entropy = self._compute_feature_entropy(features)
            entropy_scores.append(entropy)
        
        avg_entropy = np.mean(entropy_scores)
        
        # ç»¼åˆåˆ›æ–°æ½œåŠ›
        innovation_potential = (avg_distance * 0.6 + (avg_entropy / 10.0) * 0.4)
        
        return min(innovation_potential, 1.0)
    
    def optimize_creative_quality(self, target_features: np.ndarray, 
                                optimization_steps: int = 50) -> Dict[str, Any]:
        """
        åŸºäºGANçš„åˆ›æ„è´¨é‡ä¼˜åŒ–
        
        Args:
            target_features: ç›®æ ‡ç‰¹å¾
            optimization_steps: ä¼˜åŒ–æ­¥æ•°
            
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        print(f"ğŸ”§ å¼€å§‹åˆ›æ„è´¨é‡ä¼˜åŒ–...")
        print(f"   ç›®æ ‡ç‰¹å¾ç»´åº¦: {len(target_features)}")
        print(f"   ä¼˜åŒ–æ­¥æ•°: {optimization_steps}")
        
        # åˆå§‹åŒ–ä¼˜åŒ–å˜é‡
        current_features = target_features.copy()
        initial_quality = self.creative_gan.evaluate_quality(current_features.reshape(1, -1))
        
        quality_history = [initial_quality]
        feature_history = [current_features.copy()]
        
        for step in range(optimization_steps):
            # è´¨é‡æ¢¯åº¦ä¼°è®¡
            quality_score = self.creative_gan.evaluate_quality(current_features.reshape(1, -1))
            
            # ç”Ÿæˆå¤šä¸ªå€™é€‰æ ·æœ¬
            candidates = self.creative_gan.generate_creative_features(5)
            candidate_qualities = [self.creative_gan.evaluate_quality(c.reshape(1, -1)) for c in candidates]
            
            # é€‰æ‹©è´¨é‡æœ€é«˜çš„å€™é€‰æ ·æœ¬
            best_candidate_idx = np.argmax(candidate_qualities)
            best_candidate = candidates[best_candidate_idx]
            best_quality = candidate_qualities[best_candidate_idx]
            
            # å¦‚æœå€™é€‰è´¨é‡æ›´å¥½ï¼Œåˆ™æ›´æ–°
            if best_quality > quality_score:
                # æ’å€¼æ›´æ–°
                alpha = 0.3  # æ›´æ–°å¼ºåº¦
                current_features = (1 - alpha) * current_features + alpha * best_candidate
                quality_history.append(best_quality)
                feature_history.append(current_features.copy())
                
                if step % 10 == 0:
                    print(f"   ä¼˜åŒ–æ­¥æ•° {step}: è´¨é‡ {best_quality:.3f} (æå‡ {best_quality - quality_score:.3f})")
            else:
                quality_history.append(quality_score)
                feature_history.append(current_features.copy())
            
            # æ·»åŠ è½»å¾®å™ªå£°æ¢ç´¢
            noise_scale = 0.01 * (1 - step / optimization_steps)  # é€’å‡å™ªå£°
            noise = np.random.normal(0, noise_scale, len(current_features))
            current_features += noise
            current_features = np.clip(current_features, -1, 1)
        
        final_quality = self.creative_gan.evaluate_quality(current_features.reshape(1, -1))
        
        optimization_result = {
            'optimized_features': current_features,
            'initial_quality': initial_quality,
            'final_quality': final_quality,
            'quality_improvement': final_quality - initial_quality,
            'optimization_steps': optimization_steps,
            'quality_history': quality_history,
            'convergence_info': {
                'max_quality_reached': max(quality_history),
                'improvement_rate': (final_quality - initial_quality) / optimization_steps,
                'final_improvement': final_quality - initial_quality
            }
        }
        
        # æ›´æ–°ç»Ÿè®¡
        self.innovation_stats['quality_optimizations'] += 1
        self.creative_quality_scores.append({
            'timestamp': datetime.now(),
            'initial_quality': initial_quality,
            'final_quality': final_quality,
            'improvement': final_quality - initial_quality
        })
        
        print(f"âœ… è´¨é‡ä¼˜åŒ–å®Œæˆ")
        print(f"   åˆå§‹è´¨é‡: {initial_quality:.3f}")
        print(f"   æœ€ç»ˆè´¨é‡: {final_quality:.3f}")
        print(f"   è´¨é‡æå‡: {final_quality - initial_quality:.3f}")
        print(f"   ä¼˜åŒ–æˆåŠŸç‡: {(len([q for q in quality_history[1:] if q > quality_history[0]]) / (optimization_steps)):.1%}")
        
        return optimization_result
    
    # ä¿ç•™åŸæœ‰çš„å…¶ä»–æ–¹æ³•...
    
    def combine_innovations(self, primary_action: str, secondary_action: str) -> Dict[str, Any]:
        """
        ç»„åˆåˆ›æ–°ç®—æ³• - è¿œè·ç¦»è®°å¿†åŠ¨ä½œç»„åˆ (ä¿ç•™åŸæœ‰å®ç°ï¼Œå¢å¼ºç‰ˆ)
        
        å°†è¿œè·ç¦»è®°å¿†çš„åŠ¨ä½œéƒ¨åˆ†è¿›è¡Œåˆ›æ–°æ€§ç»„åˆï¼Œç”Ÿæˆæ–°çš„å¤åˆè¡Œä¸ºã€‚
        """
        # è·å–åŠ¨ä½œåº“ä¸­çš„åŠ¨ä½œä¿¡æ¯
        primary_info = self.action_library.get(primary_action, {})
        secondary_info = self.action_library.get(secondary_action, {})
        
        if not primary_info or not secondary_info:
            return {
                'combined_action': f"{primary_action}_{secondary_action}",
                'innovation_type': 'simple_combination',
                'feasibility_score': 0.5,
                'description': f'ç®€å•ç»„åˆ {primary_action} å’Œ {secondary_action}',
                'steps': [primary_action, secondary_action]
            }
        
        # åˆ†æåŠ¨ä½œç‰¹å¾
        primary_features = primary_info.get('features', np.zeros(self.feature_dim))
        secondary_features = secondary_info.get('features', np.zeros(self.feature_dim))
        
        # ä½¿ç”¨GANè¯„ä¼°ç»„åˆè´¨é‡
        combined_features = (primary_features + secondary_features) / 2
        combined_quality = self.creative_gan.evaluate_quality(combined_features.reshape(1, -1))
        
        # è®¡ç®—åŠ¨ä½œé—´çš„ååŒæ€§
        synergy_score = self._calculate_action_synergy(primary_features, secondary_features)
        
        # ç”Ÿæˆåˆ›æ–°ç»„åˆ
        innovation_type = self._determine_innovation_type(primary_info, secondary_info, synergy_score)
        
        combined_action = f"{primary_action}_innovated_{secondary_action}"
        description = self._generate_combination_description(primary_action, secondary_action, innovation_type)
        
        # ç”Ÿæˆæ‰§è¡Œæ­¥éª¤
        steps = self._create_combination_steps(primary_action, secondary_action, innovation_type)
        
        return {
            'combined_action': combined_action,
            'innovation_type': innovation_type,
            'synergy_score': synergy_score,
            'description': description,
            'steps': steps,
            'primary_action': primary_action,
            'secondary_action': secondary_action,
            'gan_quality_score': combined_quality,
            'enhanced_innovation': True
        }
    
    def get_enhanced_innovation_metrics(self) -> Dict[str, Any]:
        """
        è·å–å¢å¼ºç‰ˆåˆ›æ–°ç³»ç»Ÿé‡åŒ–æŒ‡æ ‡
        
        Returns:
            åŒ…å«æ‰€æœ‰åˆ›æ–°æŒ‡æ ‡çš„å­—å…¸
        """
        current_time = datetime.now()
        elapsed_hours = (current_time - self.innovation_stats['start_time']).total_seconds() / 3600
        
        # åŸºç¡€æŒ‡æ ‡
        basic_metrics = self.get_innovation_metrics()
        
        # æ‰©æ•£æ¨¡å‹æŒ‡æ ‡
        diffusion_stats = {
            'total_diffusion_generations': self.innovation_stats['diffusion_generations'],
            'diffusion_efficiency': self.innovation_stats['diffusion_generations'] / max(elapsed_hours, 1)
        }
        
        # GANæŒ‡æ ‡
        gan_metrics = self.creative_gan.get_training_metrics()
        gan_stats = {
            'total_gan_generations': self.innovation_stats['gan_generations'],
            'gan_training_steps': gan_metrics.get('training_steps', 0),
            'latest_gan_quality': gan_metrics.get('latest_quality_score', 0.0)
        }
        
        # è´¨é‡ä¼˜åŒ–æŒ‡æ ‡
        quality_optimization_stats = {
            'total_optimizations': self.innovation_stats['quality_optimizations'],
            'optimization_rate': self.innovation_stats['quality_optimizations'] / max(elapsed_hours, 1),
            'avg_quality_improvement': np.mean([q['improvement'] for q in self.creative_quality_scores[-10:]]) if self.creative_quality_scores else 0.0
        }
        
        # å¤šæ¨¡æ€èåˆæŒ‡æ ‡
        multimodal_stats = {
            'total_multimodal_fusions': self.innovation_stats['multimodal_fusions'],
            'multimodal_fusion_rate': self.innovation_stats['multimodal_fusions'] / max(elapsed_hours, 1),
            'active_modalities': len(self.modal_dims)
        }
        
        # æ•´ä½“è´¨é‡è¯„ä¼°
        recent_quality_scores = [q['final_quality'] for q in self.creative_quality_scores[-20:]] if self.creative_quality_scores else [0.5]
        avg_quality_score = np.mean(recent_quality_scores)
        
        # å‡çº§ç‰ˆç›®æ ‡è¯„ä¼°
        enhanced_targets = {
            'innovation_ratio_target': basic_metrics['innovative_action_ratio'] > 0.30,
            'frequency_target': basic_metrics['novel_behavior_frequency_per_hour'] > 10,
            'quality_target': avg_quality_score > 0.7,
            'multimodal_target': self.innovation_stats['multimodal_fusions'] > 5,
            'diffusion_target': self.innovation_stats['diffusion_generations'] > 20
        }
        
        # åˆ›æ–°æ´»è·ƒåº¦è¯„åˆ†
        innovation_activity_score = (
            basic_metrics['innovative_action_ratio'] * 0.3 +
            min(avg_quality_score, 1.0) * 0.3 +
            min(self.innovation_stats['diffusion_generations'] / 50.0, 1.0) * 0.2 +
            min(self.innovation_stats['multimodal_fusions'] / 10.0, 1.0) * 0.2
        )
        
        return {
            **basic_metrics,
            'enhanced_metrics': {
                'diffusion_stats': diffusion_stats,
                'gan_stats': gan_stats,
                'quality_optimization_stats': quality_optimization_stats,
                'multimodal_stats': multimodal_stats,
                'avg_quality_score': avg_quality_score,
                'innovation_activity_score': innovation_activity_score,
                'enhanced_targets_met': enhanced_targets
            },
            'training_progress': {
                'training_step': self.training_step,
                'diffusion_trained': self.training_step > 0,
                'gan_trained': self.creative_gan.get_training_metrics().get('training_steps', 0) > 0
            },
            'system_capabilities': {
                'diffusion_generation': True,
                'gan_quality_assessment': True,
                'multimodal_fusion': True,
                'quality_optimization': True,
                'advanced_novelty_detection': True
            }
        }
    
    def export_enhanced_innovation_report(self) -> str:
        """
        å¯¼å‡ºå¢å¼ºç‰ˆåˆ›æ–°ç³»ç»Ÿè¯¦ç»†æŠ¥å‘Š
        
        Returns:
            æ ¼å¼åŒ–çš„åˆ›æ–°æŠ¥å‘Šæ–‡æœ¬
        """
        metrics = self.get_enhanced_innovation_metrics()
        summary = self.get_memory_summary()
        
        # è·å–å„ç§ç»Ÿè®¡æ•°æ®
        recent_quality_items = list(self.quality_history)[-10:] if self.quality_history else []
        quality_scores = [item['quality_score'] for item in recent_quality_items]
        avg_quality = np.mean(quality_scores) if quality_scores else 0.0
        
        enhanced_targets = metrics['enhanced_metrics']['enhanced_targets_met']
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                åˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿå‡çº§ç‰ˆåˆ›æ–°æŠ¥å‘Š                                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“Š ç³»ç»Ÿæ¦‚è§ˆ
â•‘   â”œâ”€ æ€»è®°å¿†æ•°: {summary['total_memories']:,}
â•‘   â”œâ”€ åŠ¨ä½œåº“è§„æ¨¡: {summary['action_library_size']:,}
â•‘   â”œâ”€ è®°å¿†åˆ©ç”¨ç‡: {summary['innovation_metrics']['memory_utilization']:.1%}
â•‘   â”œâ”€ ç³»ç»Ÿè¿è¡Œæ—¶é—´: {summary['innovation_metrics']['system_uptime_hours']:.1f}å°æ—¶
â•‘   â”œâ”€ è®­ç»ƒæ­¥æ•°: {metrics['training_progress']['training_step']:,}
â•‘   â””â”€ æ´»è·ƒæ¨¡æ€æ•°: {metrics['enhanced_metrics']['multimodal_stats']['active_modalities']}

â•‘ ğŸ¨ åŸºç¡€åˆ›æ–°æ€§èƒ½
â•‘   â”œâ”€ æ€»åŠ¨ä½œæ•°: {metrics['total_actions']:,}
â•‘   â”œâ”€ åˆ›æ–°åŠ¨ä½œæ•°: {metrics['innovative_actions']:,}
â•‘   â”œâ”€ åˆ›æ–°æ€§åŠ¨ä½œå æ¯”: {metrics['innovative_action_ratio']:.1%}
â•‘   â”œâ”€ æ–°é¢–è¡Œä¸ºæ€»æ•°: {metrics['total_novel_behaviors']:,}
â•‘   â”œâ”€ æ–°é¢–è¡Œä¸ºé¢‘ç‡(æ¯å°æ—¶): {metrics['novel_behavior_frequency_per_hour']:.1f}
â•‘   â””â”€ æœ€è¿‘ä¸€å°æ—¶æ–°é¢–è¡Œä¸º: {metrics['recent_novel_behaviors']}

â•‘ ğŸ¤– æ‰©æ•£æ¨¡å‹æ€§èƒ½
â•‘   â”œâ”€ æ‰©æ•£ç”Ÿæˆæ€»æ•°: {metrics['enhanced_metrics']['diffusion_stats']['total_diffusion_generations']:,}
â•‘   â”œâ”€ æ‰©æ•£æ•ˆç‡(ä¸ª/å°æ—¶): {metrics['enhanced_metrics']['diffusion_stats']['diffusion_efficiency']:.1f}
â•‘   â””â”€ è®­ç»ƒçŠ¶æ€: {'âœ… å·²è®­ç»ƒ' if metrics['training_progress']['diffusion_trained'] else 'âŒ æœªè®­ç»ƒ'}

â•‘ ğŸ­ GANç½‘ç»œæ€§èƒ½  
â•‘   â”œâ”€ GANç”Ÿæˆæ€»æ•°: {metrics['enhanced_metrics']['gan_stats']['total_gan_generations']:,}
â•‘   â”œâ”€ GANè®­ç»ƒæ­¥æ•°: {metrics['enhanced_metrics']['gan_stats']['gan_training_steps']:,}
â•‘   â”œâ”€ è´¨é‡è¯„ä¼°èƒ½åŠ›: {'âœ… å·²å¯ç”¨' if metrics['enhanced_metrics']['gan_stats']['latest_gan_quality'] > 0 else 'âŒ æœªå°±ç»ª'}
â•‘   â””â”€ æœ€æ–°è´¨é‡åˆ†æ•°: {metrics['enhanced_metrics']['gan_stats']['latest_gan_quality']:.3f}

â•‘ ğŸ”„ è´¨é‡ä¼˜åŒ–æ€§èƒ½
â•‘   â”œâ”€ æ€»ä¼˜åŒ–æ¬¡æ•°: {metrics['enhanced_metrics']['quality_optimization_stats']['total_optimizations']:,}
â•‘   â”œâ”€ ä¼˜åŒ–æ•ˆç‡(æ¬¡/å°æ—¶): {metrics['enhanced_metrics']['quality_optimization_stats']['optimization_rate']:.1f}
â•‘   â”œâ”€ å¹³å‡è´¨é‡æå‡: {metrics['enhanced_metrics']['quality_optimization_stats']['avg_quality_improvement']:.3f}
â•‘   â””â”€ å½“å‰å¹³å‡è´¨é‡: {metrics['enhanced_metrics']['avg_quality_score']:.3f}

â•‘ ğŸŒˆ å¤šæ¨¡æ€èåˆæ€§èƒ½
â•‘   â”œâ”€ èåˆæ“ä½œæ€»æ•°: {metrics['enhanced_metrics']['multimodal_stats']['total_multimodal_fusions']:,}
â•‘   â”œâ”€ èåˆæ•ˆç‡(æ¬¡/å°æ—¶): {metrics['enhanced_metrics']['multimodal_stats']['multimodal_fusion_rate']:.1f}
â•‘   â””â”€ æ”¯æŒæ¨¡æ€: {', '.join(self.modal_dims.keys())}

â•‘ ğŸ¯ ç›®æ ‡è¾¾æˆæƒ…å†µ (å‡çº§ç‰ˆ)
â•‘   â”œâ”€ åˆ›æ–°æ€§åŠ¨ä½œå æ¯”ç›®æ ‡(>30%): {'âœ… å·²è¾¾æˆ' if enhanced_targets['innovation_ratio_target'] else 'âŒ æœªè¾¾æˆ'}
â•‘   â”œâ”€ æ–°é¢–è¡Œä¸ºé¢‘ç‡ç›®æ ‡(>10æ¬¡/å°æ—¶): {'âœ… å·²è¾¾æˆ' if enhanced_targets['frequency_target'] else 'âŒ æœªè¾¾æˆ'}
â•‘   â”œâ”€ åˆ›æ„è´¨é‡ç›®æ ‡(>0.7): {'âœ… å·²è¾¾æˆ' if enhanced_targets['quality_target'] else 'âŒ æœªè¾¾æˆ'}
â•‘   â”œâ”€ å¤šæ¨¡æ€èåˆç›®æ ‡(>5æ¬¡): {'âœ… å·²è¾¾æˆ' if enhanced_targets['multimodal_target'] else 'âŒ æœªè¾¾æˆ'}
â•‘   â””â”€ æ‰©æ•£ç”Ÿæˆç›®æ ‡(>20æ¬¡): {'âœ… å·²è¾¾æˆ' if enhanced_targets['diffusion_target'] else 'âŒ æœªè¾¾æˆ'}

â•‘ ğŸ“ˆ åˆ›æ–°æ´»è·ƒåº¦è¯„ä¼°
â•‘   â””â”€ ç»¼åˆæ´»è·ƒåº¦åˆ†æ•°: {metrics['enhanced_metrics']['innovation_activity_score']:.3f} 
â•‘     (åˆ›æ–°å æ¯”30% + è´¨é‡30% + æ‰©æ•£ç”Ÿæˆ20% + å¤šæ¨¡æ€èåˆ20%)

â•‘ ğŸ› ï¸ ç³»ç»Ÿèƒ½åŠ›çŠ¶æ€
â•‘   â”œâ”€ æ‰©æ•£æ¨¡å‹ç”Ÿæˆ: {'âœ…' if metrics['system_capabilities']['diffusion_generation'] else 'âŒ'}
â•‘   â”œâ”€ GANè´¨é‡è¯„ä¼°: {'âœ…' if metrics['system_capabilities']['gan_quality_assessment'] else 'âŒ'}
â•‘   â”œâ”€ å¤šæ¨¡æ€èåˆ: {'âœ…' if metrics['system_capabilities']['multimodal_fusion'] else 'âŒ'}
â•‘   â”œâ”€ è´¨é‡è‡ªåŠ¨ä¼˜åŒ–: {'âœ…' if metrics['system_capabilities']['quality_optimization'] else 'âŒ'}
â•‘   â””â”€ é«˜çº§æ–°é¢–æ€§æ£€æµ‹: {'âœ…' if metrics['system_capabilities']['advanced_novelty_detection'] else 'âŒ'}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        
        return report.strip()
    
    # ä¿ç•™åŸæœ‰çš„è¾…åŠ©æ–¹æ³•
    def _cosine_similarity(self, vec1: np.ndarray, vec2: np.ndarray) -> float:
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        if len(vec1) == 0 or len(vec2) == 0:
            return 0.0
        
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def _calculate_action_synergy(self, features1, features2) -> float:
        """è®¡ç®—åŠ¨ä½œé—´çš„ååŒæ€§"""
        if features1 is None or features2 is None:
            return 0.5
        
        if hasattr(features1, '__len__') and hasattr(features2, '__len__'):
            if len(features1) == 0 or len(features2) == 0:
                return 0.5
            return self._cosine_similarity(features1, features2)
        
        try:
            overlap = len(set(features1) & set(features2))
            total_unique = len(set(features1) | set(features2))
            
            if total_unique == 0:
                return 0.0
            
            return overlap / total_unique
        except:
            return 0.5
    
    def _determine_innovation_type(self, action1: Dict, action2: Dict, synergy: float) -> str:
        """ç¡®å®šåˆ›æ–°ç±»å‹"""
        if synergy > 0.7:
            return 'high_synergy_combination'
        elif synergy > 0.4:
            return 'moderate_combination'
        else:
            return 'novel_combination'
    
    def _generate_combination_description(self, action1: str, action2: str, innovation_type: str) -> str:
        """ç”Ÿæˆç»„åˆæè¿°"""
        descriptions = {
            'high_synergy_combination': f'é«˜åº¦ååŒçš„{action1}å’Œ{action2}ç»„åˆ',
            'moderate_combination': f'é€‚åº¦èåˆçš„{action1}å’Œ{action2}ç»„åˆ',
            'novel_combination': f'åˆ›æ–°æ€§çš„{action1}å’Œ{action2}ç»„åˆ'
        }
        return descriptions.get(innovation_type, f'{action1}ä¸{action2}çš„ç»„åˆ')
    
    def _create_combination_steps(self, action1: str, action2: str, innovation_type: str) -> List[str]:
        """åˆ›å»ºç»„åˆæ­¥éª¤"""
        if innovation_type == 'high_synergy_combination':
            return [f'åŒæ—¶æ‰§è¡Œ{action1}', f'æ— ç¼è¿‡æ¸¡åˆ°{action2}', f'å®Œæˆå¤åˆåŠ¨ä½œ']
        else:
            return [f'æ‰§è¡Œ{action1}', f'åŸºäºç»“æœè°ƒæ•´', f'æ‰§è¡Œ{action2}', f'è¯„ä¼°æœ€ç»ˆæ•ˆæœ']
    
    def get_innovation_metrics(self) -> Dict[str, Any]:
        """è·å–åŸºç¡€åˆ›æ–°ç³»ç»Ÿé‡åŒ–æŒ‡æ ‡ (ä¿ç•™åŸæ–¹æ³•)"""
        current_time = datetime.now()
        elapsed_hours = (current_time - self.innovation_stats['start_time']).total_seconds() / 3600
        
        innovative_ratio = (self.innovation_stats['innovative_actions'] / 
                          max(self.innovation_stats['total_actions'], 1))
        
        novel_behavior_frequency = (self.innovation_stats['novel_behaviors'] / 
                                  max(elapsed_hours, 1))
        
        recent_novel_behaviors = sum(1 for item in self.novelty_memory 
                                   if (current_time - item['timestamp']).total_seconds() < 3600)
        
        return {
            'innovative_action_ratio': innovative_ratio,
            'novel_behavior_frequency_per_hour': novel_behavior_frequency,
            'recent_novel_behaviors': recent_novel_behaviors,
            'total_actions': self.innovation_stats['total_actions'],
            'innovative_actions': self.innovation_stats['innovative_actions'],
            'total_novel_behaviors': self.innovation_stats['novel_behaviors'],
            'memory_utilization': len(self.memories) / self.memory_capacity,
            'action_library_size': len(self.action_library),
            'system_uptime_hours': elapsed_hours,
            'targets_met': {
                'innovation_ratio_target': innovative_ratio > 0.30,
                'frequency_target': novel_behavior_frequency > 10
            }
        }
    
    def get_memory_summary(self) -> Dict[str, Any]:
        """è·å–è®°å¿†ç³»ç»Ÿæ‘˜è¦"""
        return {
            'total_memories': len(self.memories),
            'action_library_size': len(self.action_library),
            'innovation_metrics': self.get_innovation_metrics(),
            'recent_novelty': list(self.novelty_memory)[-5:] if self.novelty_memory else []
        }
    
    def store_memory(self, features: np.ndarray, metadata: Dict[str, Any]):
        """å­˜å‚¨æ–°è®°å¿†"""
        memory = {
            'features': features,
            'timestamp': datetime.now(),
            'metadata': metadata,
            'modal_type': metadata.get('modal_type', 'sensor')
        }
        
        self.memories.append(memory)
        
        # è®°å¿†å®¹é‡ç®¡ç†
        if len(self.memories) > self.memory_capacity:
            self.memories.pop(0)


# ==================== ä½¿ç”¨ç¤ºä¾‹å’Œæ¼”ç¤º ====================

def demonstrate_enhanced_creative_system():
    """æ¼”ç¤ºå¢å¼ºç‰ˆåˆ›æ„è®°å¿†ç³»ç»Ÿçš„å®Œæ•´åŠŸèƒ½"""
    
    print("=" * 80)
    print("ğŸ¨ åˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿå‡çº§ç‰ˆå®Œæ•´æ¼”ç¤º")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–å¢å¼ºç‰ˆç³»ç»Ÿ
    print("\nğŸš€ åˆå§‹åŒ–å¢å¼ºç‰ˆåˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿ...")
    
    # é…ç½®å¤šæ¨¡æ€ç»´åº¦
    modal_dims = {
        'text': 256,
        'image': 512, 
        'audio': 128,
        'sensor': 128
    }
    
    creative_system = CreativeMemory(
        memory_capacity=5000, 
        novelty_threshold=0.4,
        device='cpu',
        modal_dims=modal_dims
    )
    
    # 2. ç”Ÿæˆè®­ç»ƒæ•°æ®å¹¶è®­ç»ƒæ¨¡å‹
    print("\nğŸ“š ç”Ÿæˆè®­ç»ƒæ•°æ®å¹¶è®­ç»ƒåˆ›æ„æ¨¡å‹...")
    training_data = np.random.randn(100, 128)  # 100ä¸ª128ç»´ç‰¹å¾æ ·æœ¬
    training_result = creative_system.train_creative_models(training_data, epochs=10)
    
    print(f"   è®­ç»ƒå®Œæˆï¼šæ‰©æ•£æŸå¤± {training_result['final_diffusion_loss']:.4f}")
    print(f"   GANè´¨é‡ï¼š{training_result['final_quality_score']:.3f}")
    
    # 3. æ¼”ç¤ºå¢å¼ºæ–°é¢–æ€§æ£€æµ‹
    print("\nğŸ” å¢å¼ºç‰ˆæ–°é¢–æ€§æ£€æµ‹æ¼”ç¤º...")
    
    sample_perception = np.random.randn(128)
    enhanced_novelty = creative_system.enhanced_novelty_detection(
        sample_perception, 
        modal_type='sensor'
    )
    
    print(f"   æ–°é¢–æ€§åˆ†æ•°: {enhanced_novelty['novelty_score']:.3f}")
    print(f"   å¤šå·´èƒºæ°´å¹³: {enhanced_novelty['dopamine_level']:.3f}")
    print(f"   è´¨é‡åˆ†æ•°: {enhanced_novelty['quality_score']:.3f}")
    print(f"   é«˜åº¦æ–°é¢–: {enhanced_novelty['is_highly_novel']}")
    
    # 4. æ¼”ç¤ºé«˜çº§åˆ›æ„ç”Ÿæˆ
    print("\nğŸ­ é«˜çº§åˆ›æ„å†…å®¹ç”Ÿæˆæ¼”ç¤º...")
    
    # æ‰©æ•£æ¨¡å‹ç”Ÿæˆ
    diffusion_samples = creative_system.generate_creative_content_advanced(
        num_samples=3,
        generation_method='diffusion'
    )
    print(f"   æ‰©æ•£æ¨¡å‹ç”Ÿæˆ: {len(diffusion_samples)} ä¸ªæ ·æœ¬")
    
    # GANç”Ÿæˆ
    gan_samples = creative_system.generate_creative_content_advanced(
        num_samples=3,
        generation_method='gan'
    )
    print(f"   GANç”Ÿæˆ: {len(gan_samples)} ä¸ªæ ·æœ¬")
    
    # æ··åˆç”Ÿæˆ
    hybrid_samples = creative_system.generate_creative_content_advanced(
        num_samples=3,
        generation_method='hybrid'
    )
    print(f"   æ··åˆç”Ÿæˆ: {len(hybrid_samples)} ä¸ªæ ·æœ¬")
    
    # 5. æ¼”ç¤ºé«˜çº§è”æƒ³å˜å¼‚
    print("\nğŸ§¬ é«˜çº§è”æƒ³å˜å¼‚æ¼”ç¤º...")
    
    mutation_types = ['diffusion_enhanced', 'gan_optimized', 'multimodal']
    for mut_type in mutation_types:
        mutated = creative_system.advanced_associative_mutation(
            sample_perception, 
            enhanced_novelty['dopamine_level'],
            mutation_type=mut_type
        )
        similarity = creative_system._cosine_similarity(sample_perception, mutated)
        print(f"   {mut_type}: ç›¸ä¼¼åº¦ {similarity:.3f}")
    
    # 6. æ¼”ç¤ºå¤šæ¨¡æ€åˆ›æ„æ¦‚å¿µåˆ›å»º
    print("\nğŸŒˆ å¤šæ¨¡æ€åˆ›æ„æ¦‚å¿µåˆ›å»ºæ¼”ç¤º...")
    
    # æ¨¡æ‹Ÿå¤šæ¨¡æ€è¾“å…¥
    modal_inputs = {
        'text': np.random.randn(modal_dims['text']),
        'image': np.random.randn(modal_dims['image']),
        'audio': np.random.randn(modal_dims['audio']),
        'sensor': sample_perception
    }
    
    creative_concept = creative_system.create_multimodal_creative_concept(
        concept_description="æ™ºèƒ½ç¯å¢ƒæ„ŸçŸ¥ä¸å“åº”ç³»ç»Ÿ",
        modal_inputs=modal_inputs
    )
    
    print(f"   åˆ›æ„æ¦‚å¿µ: {creative_concept['description']}")
    print(f"   ç»¼åˆè´¨é‡: {creative_concept['quality_score']:.3f}")
    print(f"   åˆ›æ–°æ½œåŠ›: {creative_concept['innovation_potential']:.3f}")
    print(f"   å‚ä¸æ¨¡æ€: {list(creative_concept['modal_features'].keys())}")
    
    # 7. æ¼”ç¤ºè´¨é‡ä¼˜åŒ–
    print("\nğŸ”§ åˆ›æ„è´¨é‡ä¼˜åŒ–æ¼”ç¤º...")
    
    optimization_result = creative_system.optimize_creative_quality(
        target_features=sample_perception,
        optimization_steps=20
    )
    
    print(f"   åˆå§‹è´¨é‡: {optimization_result['initial_quality']:.3f}")
    print(f"   æœ€ç»ˆè´¨é‡: {optimization_result['final_quality']:.3f}")
    print(f"   è´¨é‡æå‡: {optimization_result['quality_improvement']:.3f}")
    
    # 8. æ›´æ–°åŠ¨ä½œåº“
    print("\nğŸ“š æ›´æ–°åŠ¨ä½œåº“...")
    
    basic_actions = [
        ('æ™ºèƒ½å»ºé€ ', {'features': np.random.randn(128), 'success_rate': 0.8}),
        ('è‡ªé€‚åº”å­¦ä¹ ', {'features': np.random.randn(128), 'success_rate': 0.7}),
        ('å¤šæ¨¡æ€æ„ŸçŸ¥', {'features': np.random.randn(128), 'success_rate': 0.9}),
        ('åˆ›æ„ç”Ÿæˆ', {'features': np.random.randn(128), 'success_rate': 0.6}),
        ('è´¨é‡ä¼˜åŒ–', {'features': np.random.randn(128), 'success_rate': 0.5})
    ]
    
    for action_name, action_data in basic_actions:
        creative_system.action_library[action_name] = {
            'created_time': datetime.now(),
            'features': action_data['features'],
            'success_rate': action_data['success_rate'],
            'usage_count': 0,
            'innovation_score': random.uniform(0.3, 0.7),
            'feasibility_score': random.uniform(0.5, 0.9)
        }
    
    # 9. æ¼”ç¤ºç»„åˆåˆ›æ–°ï¼ˆå‡çº§ç‰ˆï¼‰
    print("\nğŸ”— å‡çº§ç‰ˆç»„åˆåˆ›æ–°æ¼”ç¤º...")
    
    combination = creative_system.combine_innovations('æ™ºèƒ½å»ºé€ ', 'åˆ›æ„ç”Ÿæˆ')
    print(f"   ç»„åˆåŠ¨ä½œ: {combination['combined_action']}")
    print(f"   åˆ›æ–°ç±»å‹: {combination['innovation_type']}")
    print(f"   GANè´¨é‡åˆ†æ•°: {combination['gan_quality_score']:.3f}")
    print(f"   æè¿°: {combination['description']}")
    
    # 10. è·å–å¢å¼ºç‰ˆåˆ›æ–°æŒ‡æ ‡
    print("\nğŸ“Š å¢å¼ºç‰ˆåˆ›æ–°ç³»ç»ŸæŒ‡æ ‡...")
    
    enhanced_metrics = creative_system.get_enhanced_innovation_metrics()
    
    print(f"   åŸºç¡€åˆ›æ–°:")
    print(f"     åˆ›æ–°æ€§åŠ¨ä½œå æ¯”: {enhanced_metrics['innovative_action_ratio']:.1%}")
    print(f"     æ–°é¢–è¡Œä¸ºé¢‘ç‡: {enhanced_metrics['novel_behavior_frequency_per_hour']:.1f}/å°æ—¶")
    
    print(f"   æ‰©æ•£æ¨¡å‹:")
    print(f"     ç”Ÿæˆæ€»æ•°: {enhanced_metrics['enhanced_metrics']['diffusion_stats']['total_diffusion_generations']}")
    print(f"     æ•ˆç‡: {enhanced_metrics['enhanced_metrics']['diffusion_stats']['diffusion_efficiency']:.1f}/å°æ—¶")
    
    print(f"   GANç½‘ç»œ:")
    print(f"     ç”Ÿæˆæ€»æ•°: {enhanced_metrics['enhanced_metrics']['gan_stats']['total_gan_generations']}")
    print(f"     è®­ç»ƒæ­¥æ•°: {enhanced_metrics['enhanced_metrics']['gan_stats']['gan_training_steps']}")
    
    print(f"   è´¨é‡ä¼˜åŒ–:")
    print(f"     ä¼˜åŒ–æ¬¡æ•°: {enhanced_metrics['enhanced_metrics']['quality_optimization_stats']['total_optimizations']}")
    print(f"     å¹³å‡æå‡: {enhanced_metrics['enhanced_metrics']['quality_optimization_stats']['avg_quality_improvement']:.3f}")
    
    print(f"   å¤šæ¨¡æ€èåˆ:")
    print(f"     èåˆæ¬¡æ•°: {enhanced_metrics['enhanced_metrics']['multimodal_stats']['total_multimodal_fusions']}")
    print(f"     æ”¯æŒæ¨¡æ€: {', '.join(enhanced_metrics['enhanced_metrics']['multimodal_stats']['active_modalities'])}")
    
    # 11. ç›®æ ‡è¾¾æˆæƒ…å†µ
    print("\nğŸ¯ å‡çº§ç‰ˆç›®æ ‡è¾¾æˆæƒ…å†µ...")
    
    targets = enhanced_metrics['enhanced_metrics']['enhanced_targets_met']
    print(f"   åˆ›æ–°æ€§åŠ¨ä½œå æ¯”ç›®æ ‡(>30%): {'âœ…' if targets['innovation_ratio_target'] else 'âŒ'}")
    print(f"   æ–°é¢–è¡Œä¸ºé¢‘ç‡ç›®æ ‡(>10æ¬¡/å°æ—¶): {'âœ…' if targets['frequency_target'] else 'âŒ'}")
    print(f"   åˆ›æ„è´¨é‡ç›®æ ‡(>0.7): {'âœ…' if targets['quality_target'] else 'âŒ'}")
    print(f"   å¤šæ¨¡æ€èåˆç›®æ ‡(>5æ¬¡): {'âœ…' if targets['multimodal_target'] else 'âŒ'}")
    print(f"   æ‰©æ•£ç”Ÿæˆç›®æ ‡(>20æ¬¡): {'âœ…' if targets['diffusion_target'] else 'âŒ'}")
    
    # 12. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    print("\nğŸ“‹ ç”Ÿæˆè¯¦ç»†åˆ›æ–°æŠ¥å‘Š...")
    detailed_report = creative_system.export_enhanced_innovation_report()
    print(detailed_report)
    
    print("\nğŸ¨ åˆ›é€ åŠ›è®°å¿†ç³»ç»Ÿå‡çº§ç‰ˆæ¼”ç¤ºå®Œæˆï¼")
    print("=" * 80)
    
    return creative_system


if __name__ == "__main__":
    # è¿è¡Œå®Œæ•´æ¼”ç¤º
    creative_system = demonstrate_enhanced_creative_system()