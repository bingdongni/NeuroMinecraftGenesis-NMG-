# å…­ç»´èƒ½åŠ›å¢é•¿24å°æ—¶è¿ç»­å®éªŒç³»ç»Ÿ

## ç³»ç»Ÿæ¦‚è¿°

å…­ç»´èƒ½åŠ›å¢é•¿24å°æ—¶è¿ç»­å®éªŒç³»ç»Ÿæ˜¯ä¸€ä¸ªå®Œæ•´çš„æ™ºèƒ½ä½“è®¤çŸ¥èƒ½åŠ›è¿½è¸ªå’Œåˆ†æå¹³å°ï¼Œä¸“é—¨è®¾è®¡ç”¨äºåœ¨Minecraftç¯å¢ƒä¸­é•¿æœŸç›‘æ§å’Œåˆ†ææ™ºèƒ½ä½“çš„å…­ç»´è®¤çŸ¥èƒ½åŠ›å‘å±•ã€‚è¯¥ç³»ç»Ÿå®ç°äº†24å°æ—¶ä¸é—´æ–­çš„å®æ—¶æ•°æ®é‡‡é›†ã€è¶‹åŠ¿åˆ†æå’Œç»Ÿè®¡éªŒè¯ã€‚

### æ ¸å¿ƒç‰¹æ€§

- **ğŸ§  å…­ç»´è®¤çŸ¥èƒ½åŠ›è¿½è¸ª**ï¼šè®°å¿†åŠ›ã€æ€ç»´åŠ›ã€åˆ›é€ åŠ›ã€è§‚å¯ŸåŠ›ã€æ³¨æ„åŠ›ã€æƒ³è±¡åŠ›
- **â° 24å°æ—¶è¿ç»­ç›‘æ§**ï¼šä¸é—´æ–­çš„å®æ—¶æ•°æ®é‡‡é›†å’Œåˆ†æ
- **ğŸ“Š ä¸‰ç»„å¯¹ç…§å®éªŒ**ï¼šåŸºçº¿ç»„ã€å•ç»´ä¼˜åŒ–ç»„ã€å…­ç»´ååŒç»„
- **ğŸ“ˆ å®æ—¶å¯è§†åŒ–**ï¼šStreamlitå®æ—¶ç•Œé¢æ˜¾ç¤º6æ¡è¶‹åŠ¿æ›²çº¿
- **ğŸ“‹ ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ**ï¼šé…å¯¹tæ£€éªŒã€æ–¹å·®åˆ†æã€æ•ˆåº”é‡è®¡ç®—
- **ğŸ”„ å¤šè½®å¹¶è¡Œå®éªŒ**ï¼šæ¯ç»„è¿è¡Œ5æ¬¡å–å¹³å‡å€¼ï¼Œä½¿ç”¨é˜´å½±åŒºåŸŸè¡¨ç¤ºæ ‡å‡†å·®
- **ğŸ“± è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ**ï¼šå®Œæ•´çš„å®éªŒæŠ¥å‘Šå’Œæ•°æ®å¯¼å‡º

## ç³»ç»Ÿæ¶æ„

### æ ¸å¿ƒç»„ä»¶

1. **CognitiveTracker** - è®¤çŸ¥èƒ½åŠ›è·Ÿè¸ªå™¨
   - å®æ—¶è¯„ä¼°å…­ä¸ªè®¤çŸ¥ç»´åº¦
   - åŸºçº¿æ ¡æ­£å’Œæ•°æ®ç¼“å­˜
   - å¤šæŒ‡æ ‡ç»¼åˆè¯„åˆ†

2. **HourlyMonitor** - æ¯å°æ—¶ç›‘æ§å™¨  
   - 24å°æ—¶è¿ç»­æ•°æ®é‡‡é›†
   - å¼‚å¸¸æ£€æµ‹å’Œè­¦æŠ¥ç³»ç»Ÿ
   - å®šæ—¶å›è°ƒå’ŒçŠ¶æ€ç®¡ç†

3. **TrendAnalyzer** - è¶‹åŠ¿åˆ†æå™¨
   - é•¿æœŸè¶‹åŠ¿è¯†åˆ«å’Œåˆ†ç±»
   - æ‹ç‚¹æ£€æµ‹å’Œæ¨¡å¼è¯†åˆ«
   - é¢„æµ‹å»ºæ¨¡å’Œç½®ä¿¡åº¦è®¡ç®—

4. **StatisticalAnalyzer** - ç»Ÿè®¡åˆ†æå™¨
   - é…å¯¹tæ£€éªŒå’Œæ–¹å·®åˆ†æ
   - æ•ˆåº”é‡è®¡ç®—å’Œç½®ä¿¡åŒºé—´ä¼°è®¡
   - å¤šé‡æ¯”è¾ƒæ ¡æ­£

5. **LongTermRetention** - 24å°æ—¶å®éªŒä¸»æ§åˆ¶å™¨
   - å¤šç»„å®éªŒåè°ƒç®¡ç†
   - å®æ—¶Streamlitç•Œé¢
   - è‡ªåŠ¨æŠ¥å‘Šç”Ÿæˆ

## å®‰è£…è¦æ±‚

### ä¾èµ–åº“

```bash
pip install numpy pandas scipy scikit-learn plotly streamlit
```

### å¯é€‰ä¾èµ–

```bash
pip install statsmodels matplotlib seaborn
```

## å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€æ¼”ç¤ºï¼ˆ24ç§’=24å°æ—¶ï¼‰

```bash
# è¿è¡ŒåŸºç¡€æ¼”ç¤º
python experiments/cognition/demo_24h_experiment.py

# è¿è¡Œå®Œæ•´æ¼”ç¤º
python experiments/cognition/demo_24h_experiment.py --mode demo --duration 1
```

### 2. å¯åŠ¨å®æ—¶ç•Œé¢

```bash
# å¯åŠ¨Streamlitå®æ—¶ç•Œé¢
streamlit run experiments/cognition/long_term_retention.py

# æˆ–æŒ‡å®šç«¯å£
streamlit run experiments/cognition/long_term_retention.py --server.port 8502
```

### 3. è¿è¡Œå®é™…24å°æ—¶å®éªŒ

```bash
# æ³¨æ„ï¼šå®é™…è¿è¡Œéœ€è¦24å°æ—¶
python experiments/cognition/demo_24h_experiment.py --mode real
```

## ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ç”¨æ³•

```python
from experiments.cognition.long_term_retention import LongTermRetention
from experiments.cognition.cognitive_tracker import CognitiveTracker

# åˆ›å»º24å°æ—¶å®éªŒç³»ç»Ÿ
experiment_system = LongTermRetention(streamlit_app=True)

# å¯åŠ¨å®Œæ•´å®éªŒ
success = experiment_system.start_full_experiment()

if success:
    print("24å°æ—¶å®éªŒå·²å¯åŠ¨")
```

### è‡ªå®šä¹‰å®éªŒé…ç½®

```python
from experiments.cognition.long_term_retention import ExperimentConfig, ExperimentGroup

# è‡ªå®šä¹‰å®éªŒé…ç½®
custom_config = ExperimentConfig(
    name="è‡ªå®šä¹‰å®éªŒ",
    group_type=ExperimentGroup.MULTI_OPTIMIZATION,
    duration_hours=24,
    evaluation_interval=3600,  # 1å°æ—¶
    optimization_weights={
        'memory': 2.0,      # å¼ºåŒ–è®°å¿†åŠ›
        'thinking': 1.5,    # ä¸­ç­‰å¼ºåŒ–æ€ç»´åŠ›
        'creativity': 1.0,  # ç»´æŒåˆ›é€ åŠ›
        'observation': 1.0,
        'attention': 1.0,
        'imagination': 1.0
    },
    parallel_runs=3,         # æ¯ç»„è¿è¡Œ3æ¬¡
    random_seed=42
)
```

### è®¤çŸ¥æŒ‡æ ‡è·Ÿè¸ª

```python
from experiments.cognition.cognitive_tracker import CognitiveTracker

# åˆ›å»ºè®¤çŸ¥è·Ÿè¸ªå™¨
tracker = CognitiveTracker(agent_id="agent_001")

# è®¾ç½®æƒé‡
weights = {'memory': 1.5, 'thinking': 1.5, 'creativity': 1.0,
          'observation': 1.0, 'attention': 1.0, 'imagination': 1.0}
tracker.set_weights(weights)

# è·Ÿè¸ªè®¤çŸ¥æŒ‡æ ‡
agent_state = {
    'memory_retention': 0.8,
    'learning_speed': 0.7,
    'recall_accuracy': 0.9,
    # ... å…¶ä»–æŒ‡æ ‡
}

environment_state = {
    'objects': ['tree', 'stone', 'water'],
    'time': 'day',
    'weather': 'clear'
}

metrics = tracker.track_cognitive_metrics(agent_state, environment_state)
print(f"ç»¼åˆåˆ†æ•°: {metrics.overall_score()}")
```

### è¶‹åŠ¿åˆ†æ

```python
from experiments.cognition.trend_analyzer import TrendAnalyzer

# åˆ›å»ºè¶‹åŠ¿åˆ†æå™¨
analyzer = TrendAnalyzer(min_data_points=5)

# åˆ†æå•ç»´åº¦è¶‹åŠ¿
memory_scores = [50, 52, 55, 58, 60, 63, 65, 68, 70, 72]
timestamps = [datetime.now() - timedelta(hours=i) for i in range(len(memory_scores))]

analysis = analyzer.analyze_dimension_trend(memory_scores, timestamps, "memory")
print(f"è¶‹åŠ¿æ–¹å‘: {analysis.direction.value}")
print(f"è¶‹åŠ¿å¼ºåº¦: {analysis.strength:.3f}")
print(f"æœªæ¥6å°æ—¶é¢„æµ‹: {analysis.forecast_next_6h}")
```

### ç»Ÿè®¡åˆ†æ

```python
from experiments.cognition.statistical_analyzer import StatisticalAnalyzer

# åˆ›å»ºç»Ÿè®¡åˆ†æå™¨
analyzer = StatisticalAnalyzer(alpha=0.05)

# æ‰§è¡Œé…å¯¹tæ£€éªŒ
baseline_scores = [50, 52, 51, 53, 54]
experiment_scores = [65, 68, 67, 70, 72]

result = analyzer.paired_t_test(baseline_scores, experiment_scores, "è®°å¿†åŠ›")
print(f"ç»Ÿè®¡é‡: {result.statistic:.4f}")
print(f"på€¼: {result.p_value:.4f}")
print(f"æ•ˆåº”é‡: {result.effect_size:.3f}")
print(f"æ˜¾è‘—æ€§: {result.significance_level}")
```

## ç•Œé¢è¯´æ˜

### Streamlitå®æ—¶ç•Œé¢

ç³»ç»Ÿæä¾›å®Œæ•´çš„å®æ—¶ç›‘æ§ç•Œé¢ï¼ŒåŒ…æ‹¬ï¼š

1. **å®éªŒæ§åˆ¶é¢æ¿**
   - å¼€å§‹/æš‚åœ/åœæ­¢å®éªŒæŒ‰é’®
   - å®éªŒç»„é€‰æ‹©
   - è¿è¡Œæ¬¡æ•°è®¾ç½®

2. **å®æ—¶è¶‹åŠ¿å›¾è¡¨**
   - 6ä¸ªå­å›¾åˆ†åˆ«æ˜¾ç¤ºå…­ç»´èƒ½åŠ›
   - å¤šä¸ªå®éªŒç»„çš„å¯¹æ¯”
   - äº¤äº’å¼æ‚¬åœä¿¡æ¯

3. **å®éªŒè¿›åº¦æ˜¾ç¤º**
   - 24å°æ—¶è¿›åº¦æ¡
   - å½“å‰çŠ¶æ€æŒ‡ç¤ºå™¨
   - æ•°æ®ç‚¹æ•°ç»Ÿè®¡

4. **ç»Ÿè®¡åˆ†æé¢æ¿**
   - å®æ—¶æ˜¾è‘—æ€§æ£€éªŒç»“æœ
   - æ•ˆåº”é‡è®¡ç®—
   - ç½®ä¿¡åŒºé—´æ˜¾ç¤º

### å›¾è¡¨è¯´æ˜

- **Xè½´**ï¼šæ—¶é—´ï¼ˆå°æ—¶ï¼‰
- **Yè½´**ï¼šèƒ½åŠ›åˆ†æ•°ï¼ˆ0-100ï¼‰
- **ä¸åŒé¢œè‰²**ï¼šä»£è¡¨ä¸åŒå®éªŒç»„
- **é˜´å½±åŒºåŸŸ**ï¼šæ ‡å‡†å·®èŒƒå›´
- **è¶‹åŠ¿çº¿**ï¼šæ•°æ®å¹³æ»‘åçš„å‘å±•è¶‹åŠ¿

## å®éªŒè®¾è®¡

### ä¸‰ç»„å¯¹ç…§è®¾è®¡

1. **åŸºçº¿ç»„**
   - æ— é¢å¤–ä¼˜åŒ–
   - æ ‡å‡†èƒ½åŠ›å‘å±•
   - ä½œä¸ºå¯¹ç…§ç»„

2. **å•ç»´ä¼˜åŒ–ç»„**
   - é‡ç‚¹ä¼˜åŒ–è®°å¿†åŠ›
   - å…¶ä»–ç»´åº¦ç»´æŒåŸºçº¿æ°´å¹³
   - éªŒè¯å•ç»´åº¦ä¼˜åŒ–æ•ˆæœ

3. **å…­ç»´ååŒç»„**
   - å…­ä¸ªç»´åº¦ååŒä¼˜åŒ–
   - éªŒè¯å¤šç»´åº¦ç»¼åˆæå‡æ•ˆæœ
   - æ£€éªŒååŒæ•ˆåº”

### ç»Ÿè®¡æ–¹æ³•

- **æ˜¾è‘—æ€§æ£€éªŒ**ï¼šé…å¯¹tæ£€éªŒ (p < 0.05)
- **æ•ˆåº”é‡**ï¼šCohen's d å’Œ Hedges' g
- **ç½®ä¿¡åŒºé—´**ï¼š95%ç½®ä¿¡åŒºé—´
- **å¤šé‡æ¯”è¾ƒ**ï¼šHolmæ ¡æ­£
- **åŠŸæ•ˆåˆ†æ**ï¼šç»Ÿè®¡åŠŸæ•ˆè®¡ç®—

### æ•°æ®å¤„ç†

1. **æ•°æ®é‡‡é›†**ï¼šæ¯å°æ—¶è®°å½•ä¸€æ¬¡å…­ç»´çŠ¶æ€
2. **åŸºçº¿æ ¡æ­£**ï¼šæ¯ä¸ªå®éªŒç»„å»ºç«‹åŸºçº¿æ ‡å‡†
3. **å¹³æ»‘å¤„ç†**ï¼šSavitzky-Golayæ»¤æ³¢
4. **å¼‚å¸¸æ£€æµ‹**ï¼šè‡ªåŠ¨è¯†åˆ«å’Œå¤„ç†å¼‚å¸¸å€¼
5. **è´¨é‡æ§åˆ¶**ï¼šæ•°æ®å®Œæ•´æ€§æ£€æŸ¥

## è¾“å‡ºæ–‡ä»¶

### æ•°æ®æ–‡ä»¶

- `experiment_results_*.json` - è¯¦ç»†å®éªŒæ•°æ®
- `24h_experiment_report_*.json` - ç»¼åˆåˆ†ææŠ¥å‘Š
- `trend_analysis_*.json` - è¶‹åŠ¿åˆ†æç»“æœ
- `statistical_analysis_*.json` - ç»Ÿè®¡åˆ†æç»“æœ

### æŠ¥å‘Šå†…å®¹

```json
{
  "experiment_summary": {
    "total_experiments": 3,
    "start_time": "2025-11-13T16:26:26",
    "end_time": "2025-11-14T16:26:26",
    "total_duration_hours": 24
  },
  "experiment_results": {
    "åŸºçº¿ç»„": {
      "final_scores": {"memory": 65.2, "thinking": 68.1, ...},
      "improvement_rates": {"memory": 15.3, "thinking": 8.2, ...},
      "trend_summary": {"dominant_pattern": "çº¿æ€§è¶‹åŠ¿", ...}
    },
    "å•ç»´ä¼˜åŒ–ç»„": {...},
    "å…­ç»´ååŒç»„": {...}
  },
  "comparative_analysis": {
    "statistical_significance": {
      "memory": {"p_value": 0.023, "effect_size": 0.65},
      ...
    }
  },
  "conclusions": [
    "å…­ç»´ååŒä¼˜åŒ–ç­–ç•¥æ˜¾è‘—ä¼˜äºå•ä¸€ç»´åº¦ä¼˜åŒ–",
    "å®éªŒç»„æ€§èƒ½æ’åº: [('å…­ç»´ååŒç»„', 18.2), ('å•ç»´ä¼˜åŒ–ç»„', 12.5), ('åŸºçº¿ç»„', 8.1)]"
  ]
}
```

## é«˜çº§åŠŸèƒ½

### è‡ªå®šä¹‰è¯„ä¼°å‚æ•°

```python
# è‡ªå®šä¹‰è®¤çŸ¥è¯„ä¼°å‚æ•°
tracker = CognitiveTracker(agent_id="custom_agent")
tracker.evaluation_params.update({
    'memory_window': 150,      # è®°å¿†çª—å£å¤§å°
    'thinking_complexity': 0.8, # æ€ç»´å¤æ‚åº¦ç³»æ•°
    'creativity_threshold': 0.6, # åˆ›é€ åŠ›é˜ˆå€¼
    'observation_sensitivity': 0.9, # è§‚å¯Ÿæ•æ„Ÿæ€§
    'attention_duration': 400, # æ³¨æ„åŠ›æŒç»­æ—¶é—´
    'imagination_depth': 0.7   # æƒ³è±¡åŠ›æ·±åº¦ç³»æ•°
})
```

### å®æ—¶è­¦æŠ¥ç³»ç»Ÿ

```python
# è®¾ç½®å¼‚å¸¸æ£€æµ‹é˜ˆå€¼
monitor.anomaly_thresholds.update({
    'score_drop': 15,      # åˆ†æ•°ä¸‹é™é˜ˆå€¼
    'no_progress': 8,      # æ— è¿›å±•é˜ˆå€¼
    'system_error': 5      # ç³»ç»Ÿé”™è¯¯é˜ˆå€¼
})

# æ·»åŠ è‡ªå®šä¹‰å›è°ƒ
def custom_alert_handler(alert):
    print(f"âš ï¸  è­¦æŠ¥: {alert['message']}")
    # å‘é€é‚®ä»¶ã€çŸ­ä¿¡ç­‰
    send_notification(alert)

monitor.add_callback('alert', custom_alert_handler)
```

### æ‰¹é‡åˆ†æ

```python
# æ‰¹é‡åˆ†æå¤šä¸ªå®éªŒç»“æœ
analyzer = StatisticalAnalyzer()

# æ¯”è¾ƒå¤šä¸ªå®éªŒç»„
experiment_data = {
    'ç»´åº¦1': {'åŸºçº¿ç»„': baseline_scores, 'ä¼˜åŒ–ç»„': optimized_scores},
    'ç»´åº¦2': {...},
    ...
}

# ç”Ÿæˆç»¼åˆæŠ¥å‘Š
comprehensive_report = analyzer.generate_comprehensive_report(
    experiment_data, 
    ['åŸºçº¿ç»„', 'ä¼˜åŒ–ç»„']
)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ¨¡å—å¯¼å…¥é”™è¯¯**
   ```bash
   # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸‹è¿è¡Œ
   cd /path/to/NeuroMinecraftGenesis
   python -m experiments.cognition.demo_24h_experiment
   ```

2. **Streamlitç•Œé¢æ— æ³•å¯åŠ¨**
   ```bash
   # æ£€æŸ¥Streamlitæ˜¯å¦å®‰è£…
   pip install streamlit
   
   # æ£€æŸ¥ç«¯å£æ˜¯å¦è¢«å ç”¨
   lsof -i :8501
   ```

3. **æ•°æ®é‡‡é›†å¤±è´¥**
   ```python
   # æ£€æŸ¥æ™ºèƒ½ä½“çŠ¶æ€æ ¼å¼
   agent_state = {
       'memory_retention': float,  # å¿…é¡»æ˜¯0-1ä¹‹é—´çš„æµ®ç‚¹æ•°
       'learning_speed': float,
       # ...
   }
   ```

### è°ƒè¯•æ¨¡å¼

```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥ç»„ä»¶çŠ¶æ€
tracker = CognitiveTracker("test_agent")
monitor = HourlyMonitor(tracker)

print(f"è·Ÿè¸ªå™¨çŠ¶æ€: {len(tracker.metrics_history)} æ¡è®°å½•")
print(f"ç›‘æ§å™¨çŠ¶æ€: {monitor.status}")
```

## æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ç®¡ç†

- å†å²æ•°æ®è‡ªåŠ¨æ¸…ç†ï¼ˆä¿ç•™æœ€è¿‘5000æ¡è®°å½•ï¼‰
- å®šæœŸæ¸…ç†è¿‡æœŸç›‘æ§æ•°æ®
- ä½¿ç”¨æ•°æ®ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—

### å¹¶è¡Œå¤„ç†

```python
# å¤šè¿›ç¨‹æ•°æ®å¤„ç†
from multiprocessing import Pool

def process_experiment_data(experiment_data):
    # æ•°æ®å¤„ç†é€»è¾‘
    return processed_results

# å¹¶è¡Œå¤„ç†å¤šä¸ªå®éªŒ
with Pool(processes=4) as pool:
    results = pool.map(process_experiment_data, all_experiments)
```

### å®æ—¶æ€§èƒ½

- æ•°æ®é‡‡æ ·é¢‘ç‡ä¼˜åŒ–
- å›¾è¡¨æ›´æ–°é¢‘ç‡æ§åˆ¶
- å†…å­˜ä½¿ç”¨ç›‘æ§

## æ‰©å±•åŠŸèƒ½

### æ·»åŠ æ–°çš„è®¤çŸ¥ç»´åº¦

```python
class ExtendedCognitiveTracker(CognitiveTracker):
    def evaluate_new_dimension(self, agent_state, environment_state):
        # å®ç°æ–°çš„è®¤çŸ¥ç»´åº¦è¯„ä¼°
        score = self._calculate_new_score(agent_state, environment_state)
        return min(100, max(0, score * 100))
```

### è‡ªå®šä¹‰å¯è§†åŒ–

```python
import plotly.graph_objects as go

def create_custom_visualization(metrics_data):
    fig = go.Figure()
    
    for group_name, data in metrics_data.items():
        fig.add_trace(go.Scatter(
            x=data['hours'],
            y=data['scores'],
            name=group_name,
            line=dict(width=3)
        ))
    
    fig.update_layout(
        title="è‡ªå®šä¹‰è®¤çŸ¥èƒ½åŠ›è¶‹åŠ¿å›¾",
        xaxis_title="æ—¶é—´ (å°æ—¶)",
        yaxis_title="èƒ½åŠ›åˆ†æ•°"
    )
    
    return fig
```

## æœ€ä½³å®è·µ

1. **å®éªŒè®¾è®¡**
   - ç¡®ä¿å……è¶³çš„åŸºç¡€æ•°æ®ï¼ˆè‡³å°‘3ä¸ªæ•°æ®ç‚¹ï¼‰
   - è®¾ç½®åˆç†çš„æ˜¾è‘—æ€§æ°´å¹³ï¼ˆæ¨è0.05ï¼‰
   - ä½¿ç”¨åŸºçº¿æ ¡æ­£æ¶ˆé™¤ä¸ªä½“å·®å¼‚

2. **æ•°æ®åˆ†æ**
   - å®šæœŸæ£€æŸ¥æ•°æ®è´¨é‡
   - å…³æ³¨æ•ˆåº”é‡è€Œéä»…çœ‹på€¼
   - ä½¿ç”¨å¤šç§ç»Ÿè®¡æ–¹æ³•éªŒè¯ç»“æœ

3. **å¯è§†åŒ–å‘ˆç°**
   - ä¿æŒå›¾è¡¨ç®€æ´æ¸…æ™°
   - ä½¿ç”¨ä¸€è‡´çš„é…è‰²æ–¹æ¡ˆ
   - æ·»åŠ é€‚å½“çš„å›¾ä¾‹å’Œæ³¨é‡Š

## æŠ€æœ¯æ”¯æŒ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶äº†è§£è¯¦ç»†é”™è¯¯ä¿¡æ¯
2. è¿è¡Œæ¼”ç¤ºè„šæœ¬éªŒè¯ç³»ç»ŸåŠŸèƒ½
3. æ£€æŸ¥é…ç½®å‚æ•°æ˜¯å¦æ­£ç¡®
4. æäº¤Issueå¹¶æä¾›è¯¦ç»†æè¿°

---

**ç‰ˆæœ¬**: v1.0.0  
**æ›´æ–°æ—¶é—´**: 2025-11-13  
**å¼€å‘è€…**: å…­ç»´èƒ½åŠ›ç ”ç©¶å›¢é˜Ÿ