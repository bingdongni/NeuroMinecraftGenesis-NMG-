#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½åŸºå‡†å±•ç¤ºé¢æ¿ç³»ç»Ÿæ¼”ç¤º
Performance Benchmark System Demo

è¯¥è„šæœ¬å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨æ€§èƒ½åŸºå‡†å±•ç¤ºé¢æ¿ç³»ç»Ÿçš„å„é¡¹åŠŸèƒ½ã€‚

Author: NeuroMinecraftGenesis Team
Date: 2025-11-13
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
import time
from datetime import datetime
from pathlib import Path

# å¯¼å…¥æ€§èƒ½åŸºå‡†ç³»ç»Ÿ
from utils.visualization import (
    PerformanceBenchmark,
    global_benchmark,
    create_performance_benchmark,
    get_global_benchmark
)

def demo_performance_benchmark():
    """æ¼”ç¤ºæ€§èƒ½åŸºå‡†ç³»ç»ŸåŠŸèƒ½"""
    print("=" * 80)
    print("ğŸš€ NeuroMinecraftGenesis - æ€§èƒ½åŸºå‡†å±•ç¤ºé¢æ¿ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 80)
    
    # 1. åˆ›å»ºæ€§èƒ½åŸºå‡†å®ä¾‹
    print("\nğŸ“Š 1. åˆ›å»ºæ€§èƒ½åŸºå‡†ç³»ç»Ÿå®ä¾‹...")
    config = {
        'update_interval': 30,
        'comparison_threshold': 0.1,
        'trend_analysis_window': 20,
        'export_formats': ['json', 'csv', 'html']
    }
    
    benchmark = create_performance_benchmark(config)
    print("âœ… æ€§èƒ½åŸºå‡†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    # 2. æ·»åŠ æ€§èƒ½æ•°æ®
    print("\nğŸ“ˆ 2. æ·»åŠ æ€§èƒ½æ•°æ®...")
    
    algorithms = ['DQN', 'PPO', 'DiscoRL', 'A3C', 'Rainbow', 'NeuroMinecraftGenesis']
    tasks = ['Atari Breakout', 'Minecraft Survival']
    
    for algorithm in algorithms:
        for task in tasks:
            metrics = generate_sample_metrics(algorithm, task)
            benchmark.add_performance_data(algorithm, task, metrics)
            print(f"   âœ… æ·»åŠ æ•°æ®: {algorithm} - {task}")
    
    # 3. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    print("\nğŸ§® 3. è®¡ç®—æ€§èƒ½æŒ‡æ ‡...")
    
    for algorithm in algorithms:
        for task in tasks:
            metrics = benchmark.calculate_performance_metrics(algorithm, task)
            print(f"   âœ… è®¡ç®—æŒ‡æ ‡: {algorithm} - {task}")
            avg_reward = metrics.get('average_reward', 0)
            success_rate = metrics.get('success_rate', 0)
            overall_score = metrics.get('overall_score', 0)
            
            if isinstance(avg_reward, (int, float)):
                print(f"      - å¹³å‡å¥–åŠ±: {avg_reward:.1f}")
            else:
                print(f"      - å¹³å‡å¥–åŠ±: {avg_reward}")
                
            if isinstance(success_rate, (int, float)):
                print(f"      - æˆåŠŸç‡: {success_rate*100:.1f}%")
            else:
                print(f"      - æˆåŠŸç‡: {success_rate}")
                
            if isinstance(overall_score, (int, float)):
                print(f"      - ç»¼åˆè¯„åˆ†: {overall_score:.1f}")
            else:
                print(f"      - ç»¼åˆè¯„åˆ†: {overall_score}")
    
    # 4. æ€§èƒ½å¯¹æ¯”åˆ†æ
    print("\nğŸ”„ 4. æ‰§è¡Œæ€§èƒ½å¯¹æ¯”åˆ†æ...")
    
    # ä¸åŸºçº¿ç®—æ³•æ¯”è¾ƒ
    comparison = benchmark.compare_with_baselines(
        'NeuroMinecraftGenesis', 
        'Atari Breakout', 
        ['DQN', 'PPO', 'DiscoRL']
    )
    
    print("   âœ… æ€§èƒ½å¯¹æ¯”å®Œæˆ")
    print(f"   - æ€»ä½“è¯„ä¼°: {comparison.get('overall_assessment', {}).get('performance_level', 'unknown')}")
    print(f"   - å»ºè®®: {comparison.get('overall_assessment', {}).get('recommendation', 'N/A')}")
    
    # 5. è¶‹åŠ¿åˆ†æ
    print("\nğŸ“ˆ 5. æ‰§è¡Œè¶‹åŠ¿åˆ†æ...")
    
    trend_analysis = benchmark.analyze_trends(
        'NeuroMinecraftGenesis',
        'Atari Breakout',
        15
    )
    
    print("   âœ… è¶‹åŠ¿åˆ†æå®Œæˆ")
    if 'overall_trend' in trend_analysis:
        overall_trend = trend_analysis['overall_trend']
        print(f"   - æ€»ä½“è¶‹åŠ¿: {overall_trend.get('overall_trend_type', 'unknown')}")
        print(f"   - è¶‹åŠ¿å¼ºåº¦: {overall_trend.get('trend_strength', 0):.2f}")
        print(f"   - æ€§èƒ½æ”¹å–„: {overall_trend.get('performance_improvement', 0)*100:.1f}%")
    
    # 6. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
    print("\nğŸ“„ 6. ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
    
    report_path = benchmark.generate_performance_report('NeuroMinecraftGenesis', 'html')
    print(f"   âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    json_report_path = benchmark.generate_performance_report('NeuroMinecraftGenesis', 'json')
    print(f"   âœ… JSONæŠ¥å‘Šå·²ç”Ÿæˆ: {json_report_path}")
    
    # 7. å¯¼å‡ºåŸºå‡†æ•°æ®
    print("\nğŸ’¾ 7. å¯¼å‡ºåŸºå‡†æ•°æ®...")
    
    csv_path = benchmark.export_benchmark_data('csv')
    print(f"   âœ… CSVæ•°æ®å·²å¯¼å‡º: {csv_path}")
    
    json_path = benchmark.export_benchmark_data('json')
    print(f"   âœ… JSONæ•°æ®å·²å¯¼å‡º: {json_path}")
    
    # 8. è·å–æ€§èƒ½æ€»ç»“
    print("\nğŸ“Š 8. è·å–æ€§èƒ½æ€»ç»“...")
    
    summary = benchmark.get_performance_summary()
    print("   âœ… æ€§èƒ½æ€»ç»“:")
    print(f"   - æ”¯æŒçš„ç®—æ³•: {len(summary.get('supported_baselines', {}))} ä¸ª")
    print(f"   - å½“å‰ç®—æ³•: {len(summary.get('current_algorithms', []))} ä¸ª")
    print(f"   - ç³»ç»ŸçŠ¶æ€: {summary.get('system_status', 'unknown')}")
    
    # æ˜¾ç¤ºå®æ—¶æŒ‡æ ‡
    real_time = summary.get('real_time_metrics', {})
    print("   - å®æ—¶æ€§èƒ½æŒ‡æ ‡:")
    for metric, value in real_time.items():
        print(f"     * {metric}: {value}")
    
    # 9. æ›´æ–°å®æ—¶æŒ‡æ ‡
    print("\nğŸ”„ 9. æ›´æ–°å®æ—¶æŒ‡æ ‡...")
    
    benchmark.update_real_time_metrics()
    print("   âœ… å®æ—¶æŒ‡æ ‡å·²æ›´æ–°")
    
    # 10. å±•ç¤ºå…¨å±€å®ä¾‹
    print("\nğŸŒ 10. ä½¿ç”¨å…¨å±€å®ä¾‹...")
    
    global_instance = get_global_benchmark()
    print(f"   âœ… å…¨å±€å®ä¾‹è·å–æˆåŠŸ: {type(global_instance).__name__}")
    
    # ä½¿ç”¨ä¾¿æ·å‡½æ•°
    from utils.visualization import add_performance_data, calculate_performance_metrics
    
    add_performance_data('TestAlgorithm', 'TestTask', {'score': 85.5})
    print("   âœ… ä½¿ç”¨ä¾¿æ·å‡½æ•°æ·»åŠ æ•°æ®æˆåŠŸ")
    
    print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼æ‰€æœ‰åŠŸèƒ½è¿è¡Œæ­£å¸¸ã€‚")
    print("\nğŸ“‹ ç”Ÿæˆçš„æŠ¥å‘Šå’Œæ–‡ä»¶:")
    
    # åˆ—å‡ºç”Ÿæˆçš„æ–‡ä»¶
    reports_dir = Path('reports')
    if reports_dir.exists():
        for file_path in reports_dir.glob('*'):
            print(f"   ğŸ“„ {file_path}")
    
    print("\nğŸ’¡ ä¸‹ä¸€æ­¥æ“ä½œå»ºè®®:")
    print("   1. æŸ¥çœ‹ç”Ÿæˆçš„HTMLæŠ¥å‘Š")
    print("   2. æ‰“å¼€æ€§èƒ½ä»ªè¡¨æ¿ HTMLæ–‡ä»¶")
    print("   3. åˆ†ææ€§èƒ½æ•°æ®å’Œè¶‹åŠ¿")
    print("   4. æ ¹æ®å»ºè®®ä¼˜åŒ–ç®—æ³•é…ç½®")
    
    return True

def generate_sample_metrics(algorithm: str, task: str) -> dict:
    """ç”Ÿæˆç¤ºä¾‹æ€§èƒ½æŒ‡æ ‡"""
    import random
    
    # åŸºç¡€æ€§èƒ½å€¼
    base_rewards = {
        'DQN': 132.5, 'PPO': 145.2, 'DiscoRL': 128.7,
        'A3C': 138.9, 'Rainbow': 152.8, 'NeuroMinecraftGenesis': 156.3
    }
    
    # ç®—æ³•ç‰¹å®šè°ƒæ•´
    algorithm_modifier = {
        'DQN': 0.85, 'PPO': 1.0, 'DiscoRL': 0.9,
        'A3C': 0.95, 'Rainbow': 1.05, 'NeuroMinecraftGenesis': 1.08
    }
    
    # ä»»åŠ¡ç‰¹å®šè°ƒæ•´
    task_modifier = {'Atari Breakout': 1.2, 'Minecraft Survival': 1.1}
    
    base_reward = base_rewards.get(algorithm, 100)
    alg_mod = algorithm_modifier.get(algorithm, 1.0)
    task_mod = task_modifier.get(task, 1.0)
    
    # æ·»åŠ éšæœºæ³¢åŠ¨
    reward = base_reward * alg_mod * task_mod + random.uniform(-10, 10)
    
    metrics = {
        'average_reward': reward,
        'success_rate': min(1.0, max(0.0, 0.5 + random.uniform(0, 0.5))),
        'exploration_efficiency': min(1.0, max(0.0, 0.6 + random.uniform(0, 0.4))),
        'learning_stability': min(1.0, max(0.0, 0.7 + random.uniform(0, 0.3))),
        'convergence_speed': min(1.0, max(0.0, 0.6 + random.uniform(0, 0.4))),
        'overall_score': min(100, max(0, reward / 2))
    }
    
    # ä»»åŠ¡ç‰¹å®šæŒ‡æ ‡
    if task == 'Atari Breakout':
        metrics['breakout_score'] = int(reward * 5)
    elif task == 'Minecraft Survival':
        metrics['survival_rate'] = 1.0
    
    return metrics

def show_system_info():
    """æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"""
    print("\nğŸ”§ ç³»ç»Ÿé…ç½®ä¿¡æ¯:")
    print("   - Pythonç‰ˆæœ¬:", sys.version.split()[0])
    print("   - å·¥ä½œç›®å½•:", os.getcwd())
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import numpy as np
        print("   - NumPyç‰ˆæœ¬:", np.__version__)
    except ImportError:
        print("   - NumPy: æœªå®‰è£…")
    
    try:
        import pandas as pd
        print("   - Pandasç‰ˆæœ¬:", pd.__version__)
    except ImportError:
        print("   - Pandas: æœªå®‰è£…")
    
    try:
        import matplotlib
        print("   - Matplotlibç‰ˆæœ¬:", matplotlib.__version__)
    except ImportError:
        print("   - Matplotlib: æœªå®‰è£…")
    
    print("   - æ”¯æŒçš„åŸºçº¿ç®—æ³•: DQN, PPO, DiscoRL, A3C, Rainbow")
    print("   - æ”¯æŒçš„ä»»åŠ¡: Atari Breakout, Minecraft Survival")

def main():
    """ä¸»å‡½æ•°"""
    show_system_info()
    
    try:
        success = demo_performance_benchmark()
        if success:
            print("\nâœ… æ¼”ç¤ºæˆåŠŸå®Œæˆï¼")
            return 0
        else:
            print("\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
            return 1
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())